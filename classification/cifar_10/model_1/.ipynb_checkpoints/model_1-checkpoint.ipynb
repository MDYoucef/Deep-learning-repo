{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PFE RESULTS REPRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import h5py\n",
    "#import pickle\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<array, shape=(50000, 32, 32, 3), dtype=float64, chunksize=(10000, 32, 32, 3)>\n",
      "dask.array<array, shape=(50000, 1), dtype=float64, chunksize=(10000, 1)>\n",
      "dask.array<array, shape=(10000, 32, 32, 3), dtype=float64, chunksize=(2000, 32, 32, 3)>\n",
      "dask.array<array, shape=(10000, 1), dtype=float64, chunksize=(2000, 1)>\n"
     ]
    }
   ],
   "source": [
    "dataset = h5py.File('./data/cifar10.hdf5')\n",
    "train_x, train_y, test_x, test_y = dataset['/train_x'], dataset['/train_y'], dataset['/test_x'], dataset['/test_y']\n",
    "train_x = da.from_array(train_x, chunks=(10000, 32, 32, 3))\n",
    "train_y = da.from_array(train_y, chunks=(10000))\n",
    "test_x = da.from_array(test_x, chunks=(2000, 32, 32, 3))\n",
    "test_y = da.from_array(test_y, chunks=(2000))\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "print(test_x)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dask.array<from-npy-stack, shape=(50000, 32, 32, 3), dtype=float64, chunksize=(10000, 32, 32, 3)>,\n",
       " dask.array<from-npy-stack, shape=(50000, 1), dtype=float64, chunksize=(10000, 1)>,\n",
       " dask.array<from-npy-stack, shape=(10000, 32, 32, 3), dtype=float64, chunksize=(1000, 32, 32, 3)>,\n",
       " dask.array<from-npy-stack, shape=(10000, 1), dtype=float64, chunksize=(1000, 1)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = da.from_npy_stack('data/train_x')\n",
    "train_y = da.from_npy_stack('data/train_y')\n",
    "test_x = da.from_npy_stack('data/test_x')\n",
    "test_y = da.from_npy_stack('data/test_y')\n",
    "train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_batch(cifar10_dataset_folder_path, train_or_test, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + train_or_test + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return np.asarray(features)/255., np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<array, shape=(50000, 32, 32, 3), dtype=float64, chunksize=(10000, 32, 32, 3)>\n",
      "dask.array<array, shape=(50000, 1), dtype=float64, chunksize=(10000, 1)>\n",
      "dask.array<array, shape=(10000, 32, 32, 3), dtype=float64, chunksize=(1000, 32, 32, 3)>\n",
      "dask.array<astype, shape=(10000, 1), dtype=float64, chunksize=(1000, 1)>\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = np.empty(shape=(0, 32, 32, 3)), np.empty(shape=0)\n",
    "test_x, test_y = np.empty(shape=(0, 32, 32, 3)), np.empty(shape=0)\n",
    "for i in range(1, 6):\n",
    "    tmp_x, tmp_y = load_cifar10_batch('/home/skyolia/JupyterProjects/classification/cifar_10/data/cifar-10-batches-py', '/data_batch_', i)\n",
    "    train_x = np.vstack((train_x, tmp_x))\n",
    "    train_y = np.hstack((train_y, tmp_y))\n",
    "    \n",
    "test_x, test_y = load_cifar10_batch('/home/skyolia/JupyterProjects/classification/cifar_10/data/cifar-10-batches-py', '/test_batch', '')\n",
    "\n",
    "train_x = da.from_array(train_x, chunks=(10000, 32, 32, 3))\n",
    "train_y = da.from_array(train_y[:, np.newaxis], chunks=10000)\n",
    "test_x = da.from_array(test_x, chunks=(1000, 32, 32, 3))\n",
    "test_y = da.from_array(test_y[:, np.newaxis], chunks=1000).astype(np.float64)\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "print(test_x)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.to_npy_stack('data/train_x', train_x, axis=0)\n",
    "da.to_npy_stack('data/train_y', train_y, axis=0)\n",
    "da.to_npy_stack('data/test_x', test_x, axis=0)\n",
    "da.to_npy_stack('data/test_y', test_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.to_hdf5('./data/cifar10.hdf5', {'/train_x': train_x, '/train_y': train_y, '/test_x': test_x, '/test_y': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHVCAYAAAApYyiLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzsvWmsJNd5pvmdWHLPu1fdWllFUiS1WpJFy7uAllsYT/8YqYHuGRuDhhoQIGAAA3a3gTHtxgzQgH9o+of9x5g2CFiQGjCs9rSNluCx2yBk2R7PdEsqSSRFiiJZrCrWfvcl98yIOPOjLuve971Vd6+MrKr3AQjWdyMy8mTEiXMy4z3v9znvvQkhhBBiuAR5N0AIIYR4HNEELIQQQuSAJmAhhBAiBzQBCyGEEDmgCVgIIYTIAU3AQgghRA5oAhZCCCFyQBOwEEIIkQOHmoCdc7/snHvTOXfROffCUTVKiJ1QvxPDRn1OPAjcQTNhOedCM3vLzD5jZtfN7Ltm9qve+x/d7zVRFPpCHN2N4yiG7YVCAWJuWpamEKcZxWlGr9/tszmKcX9Hm922P/B2jAOH32+CAGM+Hrc2o/b7DD9fmiS2E4VCBHFMsYvCHdvLn2c33Lbzidy4sbDovT+2v6PSe+yz302M1/2JE9N340GC5zRJ8JxmGV0F+ki83dHu1UoV4pDOcavThrjf70PM90CpVIR4MMBr3mg0dmxvsYivd3SNt91kjxjXr10fep8zMysWYl+pFO+3eeTgO5fvfU8x3ze93gDiON5l7AlpbKPjD/o4tmd03/Jg6Q3bE4Y0ltHYy/dlGGID+DZxAY2VAc5d3XYX4vXlxp76XbTbDjvwSTO76L2/ZGbmnPuamX3WzO7bKQtxZO8/f/puPDs7C9tPnz4DMc2v1mg0KcbBp9nE7f0+dgrzO0+AZviGDs+5FahThXgNLKKLWiqVdoxjGmwHNBj2B9j+XqsD8frKCsT8OOP0mQmIT5w/DnFxoo5xuYztDeim2WWsDoKdJ+DffuEP3935CHtiX/3uxIlpe/H//Dd347llnMCWlvHGaXV6eAA6qd0uTphhgjt88uPPQzw+PQnx915/BeIrV69AfPYM3gPPPvssxLdv34b47/7u7yF2NPA89fTTEBdi+pLLXzgeMX7z1/7V0PucmVmlUrRPf+rDR/DWDwi67CGNhXGMO6Q01i0u4n1w6Z1rEB+fxbHm1HmciwoTeB8mDifQW9fXIG4u4tjs6QtA6vCLbX2Cxt5KBeLa+DjE4xP4ZSku4+cvjeFYWimdgPiN7/8Y4v/yx3+zp353mEfQp81s61m/vvE3wDn3RefcBefchSRJebMQ+2XXfre1z62u0i9EIfbPvse6Hn/5F+IeHGYCvtfPnW1fp733L3rvn/feP8+/EIU4ALv2u619boJ+5QtxAPY91hUL8T1eIgRymEfQ183s7Jb4jJnd3OkFzpxF0eZbrtAjVH4cVi7XIG7RI9h2uwUx62msue6mS8Qx6QJ0dlhXoMNbHONNx/od63H8SNt6+Ai9WqP9j6G+uD6O78eP5OMibq/V8DFKWMTHNKwPOgtpu9F2jvcpGh+MffW79dbAvnVh7m7camAfGvTwkXOW4vZCGR/ZZvSddbqO5zQmLarYxV9CE6QdVQt4DRaXliCu3LgBcRBhnynXsU/cvI7712t4D7Hsw/eIuCf7HuuE2AuHufu+a2bPOOeedM4VzOxXzOwbR9MsIe6L+p0YNupz4oFw4F/A3vvEOfdrZvbXZhaa2Ze9968fWcuEuAfqd2LYqM+JB8VhHkGb9/4vzewvj6gtQuwJ9TsxbNTnxIPgUBPwfgnD0MbGxu7GS0uLsH1hEeNSCZeWZylqxD3S70ISbVmDLZMvr1RGPa5ImmkU7ewNY9jDWSbbUZlsPrUKbh93uDS+TLaoXhc/b6mP56eQ4OdPitieiHxTUYznI83YR02f3xBPf9nNhpQHzsyiLUpLucx9gjTelHyz5A/s9dE+MT01BXGBrFsp2Zqma3iN12fQBnV1DqXFty9ehLg+SfaJKbQ5zc3NQTw/Pw9xjTThahU1ZHF08BqKUSYz7NcZ2YI8hmYB/qE6gWNbSmNXh+x7seHYFzoau0M8fj/E9T4B26Ro6IkL5R1j9vOvruD6maiB28cTHBfqZ7F9x5/AtSB7RSswhBBCiBzQBCyEEELkgCZgIYQQIgeGqgEHYQAa1Po6PndnTbfdwuf+rEmy77ZaxXRj1RqlIyPNt0L6X6GIp4MTh7AGHJHmXChQOjPybNbrmBRienoa4kGHcjtHeLzTpDeeonRs7165DPFiEz2l5vHz+Iw0Xjq/fL45XyunEW6TT3sUiOOCnTi1mbRojjTRVgu91wHp5CFdwwppY8dmMSVd7RSm4POUEWmsjJ1oKsM+v7S+DvHKOqbkG/Swj9Rr2KdmJlETXl9ZhbjJuaPFA8E5Z3E4uhow55lPSERNaWxIKRfzIMN+OH4C1xLE5HcfJNjPfUr7s2ZbxLEkxqHdghjbN17DVJdjk5TzgNZyeMrKOOjhepruKo4Li4s4bmRdfH08cbBrrV/AQgghRA5oAhZCCCFyQBOwEEIIkQND1YCzzFu7vekHc+T9Itsq5I02M+uTB5PL+9XqqCNUa5ybmcsFkmZLPt6IcjUHpPkG9P0lofKBXPspDqg+6ABf36UamLcXsPTcrSXMnV2g3NIDat+JJ7AU3QLpGI3bqDeOj6FH1JEPepCgl291DfXEuVt4/FGg1+vZxYvv3I37fdKiKKd+pYxi0yRpSU+dfxLi950/D3Gd1gG0ussQD6im9RTlO//guWcgNlqXwLmpOZXzTzyF5Qv7VD/YU01JN4Le7UcC78370a2IlHFtccqx4Ggs4RwEvQGOBROUp36yPgbx+hKOFYFH//vYOO5vEeVQmMTjBxHeB2GMayFKJdqfPm/YxbhDY29jFcfa1iKVul3Hz185QyL1HtEvYCGEECIHNAELIYQQOaAJWAghhMiBoWrAaZLa6hZfYreLOoAjfYo1WNZoHRWojaieb5n0sm25n+l4cUwxFdVOE9TTmuuo7/V66F2bGEffrqN8q2VqT7mEMe/PmmtvgLpMRJrw8jJqvIsL6AntdMhnTb7iWh11jeUl/LwL8xivrY2exzQMAhvbku945oknYPvkBPpmxycw1/L0JF5Dzp3M2tiNNdTtPeXr5qS6AXlFA0decOrjGWnIJG1ZRv7GdBmvebeL7Um4yLM4Erx5S+j+HSUyWvvAqZ4TWjuQGOrZEQ5V5jt4vDWqbd6h+yCk/f0i5Sig2uuFEq7vKdHYng44KQG+n+vhJ2yt4di3sox++ybXDacFPX4V73tHc8Ve0S9gIYQQIgc0AQshhBA5oAlYCCGEyIEh+4Aza295Nu8pH2lMmm+SoO5QraBXrEv6W4NySx87jvuzb5hzNUfkiRy08Xgpaa7jKEtYeRr1xLiAGmqhSPVzY/z+UyRhZSZA/XFiEnNH90j3SDweb5r2P33qDMRXr70LcUa+xfnbCxDfuIH6Zodq3XY6qOmPAsVi0Z5+atO7W62ghlsg7aZOGm+FajYn1Afe/PEPIL5+9TWIw225o9GbPXXsHMRdqoM6d+MaxCurqLs3ScfvUK7nAq0DCAPU2hLywoujI/Wj+/uG/e8B9VOOQ6r9zfV70yZqxg0aO30Rz0Wvi/02vY1xhepWl2h9TJ9zRXtaT5OiRtxfx/t2fh5rz681aW1ESvWQ6bdq1qfzs3SwtRSj20OEEEKIRxhNwEIIIUQOaAIWQgghcmCoGjBTpry7rLcZ560lzyLnQu50dq5HWyiiaMtpcP0ANcyQNNFTs6jJTk9S/tEKfp5+irpEFuD7VyqocwzIKxcE5Msto0d1LMbXe6Pc13R+HOk4EdW+vUm5nK9cQY24T7VtWcN3AWe/zp9ev2fvXt38HOzW4xsgopy4VSoCPUY1nVdbeM5uX78CcZPqDa+QVnbOKKct5bhdb6I/cW0Nfb0Nqpm9uIi6fUB+zjL5KS3DnLbiaEgzb81mb/cdcyKkwa9YwH4e0FjB3WR1BftdlcaayNFagx4en227lTFce1EyPJ5v47nsk9+9EGLsaHtjEddCrM/hWNuj+yQjDZzrEpCd39rZwWqh6xewEEIIkQOagIUQQogc0AQshBBC5MBQNeAgcFYub+q8ZdJ8qxXUp+IiKnYJJeQckCaZpahbLC9iTcfxcaztGsWcZxd1gPEaaro1rh9M318KAX6e8089B/HU8fMQ9xIUQm7PXYZ4ZQX1vF6P8rOSMFMu4/ljr16njTrFu1fRY3r16hWI2y308pUr+PlDOn9TNarpOQIkna7Nvfqju3GVruEY+X4bVOe0yeIXfWVNSKcvFlAjjqvoDa9VUcenVNBWpfzbZ544C3GdNOi1NdSIA9K+VpfRN9znrL+kxYmjwXtvg8EI54IO2NdLeehpvU1AY0kQk388xrFvmsbaBfKvD8hPbwFNRRneGFkXO2pI1daLVdJoHc4NvYzWr3ASdRqLM1rfknLOdbpvovBgv2X1C1gIIYTIAU3AQgghRA5oAhZCCCFyYPgacGVTayiVcf6v1LA5FdLDClSvt9NA325jDV/fWEHNc3V+CeJjM+Q9I5Pok2dRf+uRzzgLUQc58+QHID79xAchTj3u3ycPZ6U6A3GnSzUs26hpd7uo/3U66G2bHMdc0Ky7rK3g8Tpt9KwG9PWsVMbzOzWNOk+NNPNRwA0SKyxs5n2tvA/rAbepzunSIua7/jBprB8lXe/KOGq67hMfg3j8fe/DuIbnrEj5yS1DbatCfSyh/Ntz8+hDtgi1s0IZj9+iGty8jkAcDYFzVuQBZYTgnAC0dMBSqjsdlbEfzpw+DvH01CzEH3vmoxBfvPgGxC+/+TLEK6vob18lzbce4fufPoFrK47XMb556ybEjmrF1ybxvvBr5OMd4PlJM04aQT7q6GBTqX4BCyGEEDmgCVgIIYTIgV0nYOfcl51z886517b8bco595Jz7u2N/0/udAwh9ov6nRg26nNi2OzlwfVXzOwPzOw/bPnbC2b2Te/9l5xzL2zEv7XbgVzgrFTe1EUqVXyuX63hc/lKFeNtuaNLGIeUt7fdRI11bWkO4rEK3kvnnkF9cGoGfa3FCHWOQUC+YKpX3E9RdxiQmYxrTvLlcOTNCyl3c6+HPt0kwc/LXrdGA/XMLtXkNI+6T30MPaezJ45BfOIkxqzRH5Kv2BH0u8SnttTZ/Ny3X34Vti8u4rqA7jJqUdOU9HXuJOr0DTonfdKCOlRnNO6ghuzJu83aXGMNc9heuPBtiL/zKtYjLlfxnpggPyb7Ozl+zPmKHdFYZ85ZQLrjKOHJyOpp7UEWkC+WcyOXcSyqTeFaiOc+iGshzp97BuKE3v/a1asQ9w3XOpw7jWPzT338ExC31/E+fvPiFYgLtL7IhaTxkj8+W8P3jzKcW8IQx7rCAYe+XX8Be+//3syW6c+fNbOvbvz7q2b2uYO9vRD3Rv1ODBv1OTFsDqoBz3rvb5mZbfz/+P12dM590Tl3wTl3YZQzw4iHgj31u619rkvZ0oTYJwca6/p9jXVidx74Iizv/Yve++e998/Hca7VD8VjwtY+VyqMrhVEPFps7XeFgsY6sTsH7SVzzrmT3vtbzrmTZja/6yvMLAgCyCdcZY2XckNzvV8XoKZSKmLzw4g0VYfP8acnUW87exr1u5jG6mvXUZcoV1DnsBjjiWPYPk+a9IC8dS7C7bt9QQnImFsiDynX600ptzVrvhnlR62QBn/yFGm+J1ADr5HeyDUzHwD77nfletU++I9++m589XWscXzrJubbdtNY8/nScfLtfhC93jPPYZyQZjx/8wbEZG+0kHy6GV3TtVXU+S9ewXzhly9hPDmJ6xrKBTzeJH2+And6wRxorPPeW28wwk9fWANmIzCtDUj7OJaGbfIR09gTUZLzk2efhPhnf+rnIX7fWfTLB+SzfeIJfP2xaXwQ8Rdf/1OIVxuY02BsisbKHvrfI8pFXYzxfIRUSTyksTooHSyp+kF/AX/DzD6/8e/Pm9nXD3gcIfaD+p0YNupz4oGxFxvSn5jZfzWz55xz151zXzCzL5nZZ5xzb5vZZzZiIY4M9TsxbNTnxLDZ9Zmh9/5X77Ppl464LULcRf1ODBv1OTFshp4LurJFA+b6sgWq/xsEO/voHNVirdbweIFHzffJJ05BPFEnny/Vim13Ude4eRs9os9+8GmIp2dOQhxSjUxLOA8vec+oOGtG2z3VqKySBlssko5DxyNJ2uICnt+pOuaOnplBvbBURLPbw+ApLZXL9txPfOhufO796E987ud+FuJGF3PCzi+hv7BGWlbtGPqCb195G+KrlJO2RdpUl+oPHzuGunu9UoO4QDl5J6dQ86UuYn06fkjrCHa7x8TB8Lb9fh0pqG3c1m13MvmE+028T9rkn5+/fR3isRLncsaxcmaMarVTvxyjvPbz5N9/8523IG5Q7fOQ1gv1u/h5Co7mIjL2ZlQv2FMO+aB4sLUUSkUphBBC5IAmYCGEECIHNAELIYQQOTBkDTiw0hYtoFDgXMeoPASsMW7TVEgDJl/xZB1j1r9Wl1GPy9ZRN3ARaqwf+djPQfzhj/40xGGM+3d72L6UdBT26fb6pNeRl65QYF80np8CnZ/BAD9PkqKXb3wCcz1Pz5CHlPIUszCUkeeVNevRwFmQbuo5/JlOPIk5Zsc6qNOfOIM1oSfG8RzVaqjRRqR1eYfX8CrlvI0T8iNGeE80mugDThPsMxMT2J421azuUv3f23NY7zhJed2AOAqcjeaaiPfwjsbSXe7tlDTQ/gD7zRrVWl+cQw34LOWNr1awn5dj9hVjP19vYIbQNy++DvHyKmUQJU3XhbjepzaB92VMc0NCPuGkh/fRYICxDw429ukXsBBCCJEDmoCFEEKIHNAELIQQQuTAUDVg55wVt3hJA9LHfIY6gKf6tN6zpkLbU/RmlaukYbI+R16z6ZkzED/zAfSMnqF8pWFchTgZsJ6GOobz2L5uG3Mzr65ivd4+VY9yIV4uT8LNIEXdotFBjdtFqOMcP4X5VNn7xrmqSXK3tE81QvH0jgTJILXF+c3zmhSwPm+XNNhqFa/pqdPYJ6anqAYy5W420u2PzVC9YNKS1tbxmndIw11dWaHXo44/MYH+yZiuIb9fo0E1pKUBPxC895YMRnFNxB221QMe7Lyeg+v38lqELvXbxjqtr6G82L0ubifJ2QpFHLs5F3WvT2s1Tp2GOKLBaGIS/foB1Ttmn3NK7W238L5ZX0XNu51SbfU9ol/AQgghRA5oAhZCCCFyQBOwEEIIkQPD1YDNWbCl7iJrulm6szctcJy/FLenKedSxgO02qhbnDiF+Ug/Qr7e6ePoATVjfQ11goT0xG4P9cbVlUWMybvWWF+HOCA9kesBD0inaDVRV2m1UbcIQ3x9vYY+YJ+x9490oD6e36kx9KBOTWLu6FEgyTJb3uLtLcd4DaenUBuamsbPVK/jOeqRFnX1OvodX3n1VYh/+BrGt25jbuhuF/sI+5RjqrHMNZ85VzT3mdUE9+fc0OlIercffrw3S0a4HDBrwLyew6cUc04GGov6tP7k9hyOdc11PBljtNaiXMEcCpVxrLXezbAMc41qsz/15HMQc45zPr6jPPkJ3yeUk6FSRR9xdQxzUy8tzRnypu0F/QIWQgghckATsBBCCJEDmoCFEEKIHBiqBmzOmXObOUA9mb/IWmY+w+fyGekSjnzC7SZ6KtsN1NfOPnEe4hOz5yAul1HvG5DexrmcB6QHJgOMGy3UdJeXFyDu9dA7l1J+0cBjvtQ+5Y5eX8Pjd6mWbZeOn1Buas41Xa3i508S9iFDaB943wcgXllFz+ooUCyV7Mlnn70bl8ukBdFX0C75bG9fugzxrVuYS/ny5SsQX7txDfe/iZpvs4U6fZF8u3GM2hRf0z5d0wFpuBFpxpyPOMtY+6KbThwJ3psNBqN7bjPyfyekeXKq6CjGGyUsYL+KCrj91q0bEL/2xjsQ/8SHP46vL6Kfvo3Nsd4AG1Qpo4Y8O4vrebi+MdcB6NNYzfdNSDkXooju0yLV6abY7Fu2F/QLWAghhMgBTcBCCCFEDmgCFkIIIXJgqBqwzzLrdTcf7vNzdvZe3biBehvXAz5Ons1SkXSB4+jxZP3ryuVLEI9PoY+1Wkev2YDzp3KNTNIPF8gb1iSNmn25GXnR5kg/vHEDdRXWLVhP5LzGJ2ZOQDw5heePrHG2uIRevqUmxhdeuQBxq3WwfKgPkjRNbXVt87yzb5c/4xp5sdlrvd7A7QuL+HrOtcy+3LEx7FPs7WZfbrvdoRiPH1NN7clJzA3N9YBZ8+V1GOKo8Nt0yJGCm8YpGDgHA3azbfWEO21cb2NdzHFw+epbEJ8+hznWswD7adTD+4LXy1Qq6JfntQ583/JYW0jxA/F9wutjvOHYvq0sQXCwqVS/gIUQQogc0AQshBBC5IAmYCGEECIHhqoB9/sDu3Hj1t24Poa+U36OnyboVTt9Ar1eJ09gPVuS07bVt222Ub9r30LNMvke6gYzx/D4EeURLhax/f0e6muNBmq+gwR1hgHVap2/hZrx5XfQO9cg/fHECdR0T5AX7sTsLMTTM5i/dHERa1reuIH66Pw8tqczQJ2nVMaam/VxPB+jQKvdtguv/OBuzBrtwjx6s1eWUbva5pPdlhOXYtoex6g1sebL2hPXA2bfcIdqSM/OYh/l+sBLS3iNG3S8UdTtHxlYJxwlaKzk3M6UStkKZfTpugh3WLqNOQA8HW9lFdfzLCy9C/HpEx/G9+fBPMOxd0B1uLtd1Gj5PuS5IAzLO27ncSLl9T8hieakGe8V/QIWQgghckATsBBCCJEDmoCFEEKIHBh6Lugg3nw2H5fIx1pCTfH0SdQ0SxFuTymfabGIz/U7pLEm5LH0ZH67eRN9tq3lVdyf6v/2SUfoJlxTE/XDiRrmIV5bxeOvLKNmPE71emsV1BOrFdRBuL7yO5dRQ37jndchbjZR/9vmI55AH/FUCX3D7EMOwtH7PtfptO2Vl1+5G7Mm2iX/YqmAfWzm+DGIZ6lPRjGeg6VF1JA7HfYX4jXMKIduv4deeNagu13c3mqhZrxKfWqdfM3NRnPH7eJo8GaW0Pg0UmzzKFN9YGo7pd23UhHHsjjEsSTLsN/2ElrbQH72YhlzKUeOxpaA6/Viexrr2K+jEN+/EOF952jsysgPXyKNuVxD/35CteZZg94rozdiCiGEEI8BmoCFEEKIHNh1AnbOnXXOfcs594Zz7nXn3K9v/H3KOfeSc+7tjf9P7nYsIfaK+p0YNupzYtjsRQNOzOw3vfffd87Vzex7zrmXzOxfmtk3vfdfcs69YGYvmNlv7XSgQiGyk6c2valF0tuKRYodPrfvUW1U9m51OqhDcG5prmfL+U9ZE47J69Zt4vtfv45etpBqzXrK7ewHqHPUKJ/p8fc/C3Gni/rk1WvkC27h9uUV/PxRBS/viVOoZx6fxZi9cxwznOuW6zUfkiPpd1mWQZ7aE8fRG12roc5dKeE1maB82ST9bKsPvE5a1IDWBZRL2Ke4rimf8nX2I6a4TqDVxD7QJk2Yfcizx9E3PDX5aM8lP1x6bT+7H9lY51NvvUZ/p11yJSCTchTwvY6ib69FuZDJHh8FOBaUaziWJxmei9sLmGPg1vw8xFPjmJefaytnbMOlsTpl+35IOSaotns6wPbFdDpYE+916fUHHPt2/QXsvb/lvf/+xr8bZvaGmZ02s8+a2Vc3dvuqmX3uQC0Q4h6o34lhoz4nhs2+NGDn3Hkz+7iZfdvMZr33t8zudFwzO36f13zROXfBOXeh0x3db4RidNlvv9va5/ibsxB74bBj3UivgBYjw54nYOdczcz+zMx+w3u/Z++C9/5F7/3z3vvny6XC7i8QYgsH6Xdb+1wcD9dpJx5+jmKsiw6YmlA8XuxpdHLOxXanQ/6x9/7PN/4855w76b2/5Zw7aWbz9z/CHYIwtLHxTR100EGNtLmCfT0hjZc1314f9a6MfL7BNg2TNEvSMD19a+1TTcmZGawv3M3wJjv3zDMQLyxQ/tNF1D3aA3r/DrZ3fQ31xB7tz7bbE6cxN3RtHDVp1sC3ef1Y08121jX2qxnvl6Pod+VyxT760Y/ejfkzLy2jL/idd69AvP7aqxDzugLzeFILBdR0C5Q/3PsuxXi4gPyPY3XUaNuk+Tab2EfYj1googbcWEdNmXPePu4c1VjnnZkfYY9JapSzwJEPtoD9MCaNmCeOch37fY3ilAafJcoz/8Mf/gDij3zoYxAHVJC438f7OCENtjfAuEBjGfuUW+uYy7q9Qnn8U7yYA1qfVK4dLA/+XlZBOzP7IzN7w3v/e1s2fcPMPr/x78+b2dcP1AIh7oH6nRg26nNi2OzlF/DPm9m/MLMfOude3vjb75jZl8zsT51zXzCzq2b2zx9ME8VjivqdGDbqc2Ko7DoBe+//we5fWOuXjrY5QtxB/U4MG/U5MWyGu0LFZ5ZsqYk7dwullMhT/s8J9M3yugbO37nN1+uCnbfTH1jDnBjH/J+zE6gBnzpzHuIWacZXO6jPZQ51i8U11BmOxdjehNrnDXWHhDVb0nGM4iTZWdNlDXg3eP/tmnv+9Ho9u3jx8t14fgHr/y4uYdwl7zX7C4sFzBFbKKDOHu3SB2PKBV0qsU6P+5eqqC3F5J2/cvltiK9TTWcuq7pENaAPmsNW7EwYB1Y9Wdt9x5zg9SBRATtuRBqqrdF2Wv9SifG+KIUY9ygnwoByOszdvgbxLPn1pyZxfcviAuZcb7b4vsX7bCykBcCUYz3goY8+fo9yxvdIU07Tgzl8RniZgBBCCPHooglYCCGEyAFNwEIIIUQODD9Lgdt82F6heraOvFaevVtUlJI1Va4nzJpvv4vP/RNKKDozjflHJ6cwXiD9bJBhPL+CXrKlFdz+9LPvg/iNN9+A+NLlyxBnKeoYxQJqSgnlL21TLuxqHfMab5d4d9Z8WePdVSIewa9z/f7Arl2/eTfO6JpHpMlyTekwZJ8v9rGQ64o6PH5MPtxjlIv52DGMB+RP5HUJY5S7ut3CdQQvXcE2AAAgAElEQVQ3b2J+8oS0t2qVajxTH3/UuHb5+u47PQC8N/OD/a2pGCYlyrs/MY1jS/M2jmXpgHMG4PEGHcqhYNjvHPmIS5QTPY5wO6/PaZMGu7KM7VtZwxwS1foExNPT+H4J51QI8XyMz+B9WRjD+7KxjnW3eW3JXhnBIVMIIYR49NEELIQQQuSAJmAhhBAiB4arAbvAomhT962gzdYy8qkWqHlZiM/hT57H5/Qf/dhHIG6vYd7dm+8u4htSHl8j/e7mIuZyXiGN9/r1WxA32/h+46RDXL6EetTaMnrhmk3UTWpV1MizDLevN7A90zPoGfWedJVdNd3dNOEdN++uEeeAcw5yiHN6a9ZYa/EYxNUKamOsGfep2lJAxR9OnED/4hNnn4B4YgJvAr7GrIWtl9HPuLSExx8MUCvja1qpoO+Y6wU/auSlAbvULBrhNNvBLkXC4jZqooWQNFMcmiws4lg6MTkN8dNP4vqX8jiutbACvr5Eay3m5zB39O35GxAvLKIGWy7hWFirYr+fmsT7zpVwbUQY4n1cp1zUVsD2Lzdw/c1e0S9gIYQQIgc0AQshhBA5oAlYCCGEyIGhasDOnEW2+ex8fAyf05eLKCwUQ8rNPIvP6Z947hTEx2cxV3O7hnpYRrmUG/TcPiYd433T5yFuNlHUiX+AOsBrr/wY4sVlzFdapHylBdIRSkX8vEmC3jqSJe7hUWXNmGtg4vG2550/nIi7S/ngXHDOWbQln3OljFoQ54xln+zEBGpZAWnAjRbm+45JAz73xFmIZ48dg7hAuabbbexjiwuYL33u1k2Ikz6uO5icwHUHMfmUQ8o1fdQ1nMUGmbesy/fb6NDrYw7w1Q7VB6b6uqUirj2Iy3gf+CL562u4feYE9vvKOK6tGFDe+uUF9PVeufIOxFdvXoG428exvFzB+/jmHL7f7IlPQlyt4H3TalGtearT7WIcR0r1g/np9QtYCCGEyAFNwEIIIUQOaAIWQgghcmCoGnCpWLZnn/zQ3bjI+Ugn0IOZeXyuH1TRvDY2ift3B6iHDQz39yHqDEERv39MzKAOUJ9CjTqj1585fRri+Vvoy711E33C7Ln0lJeYt3c6qBkPmvj5CgXSJUjO4zzArAnvpv/ttn1bPeBg9PTEYrFgT53f1GFL5PeLIuyDpTLp8qQJByTETw6wz1Qpv/n0JG4PqfDo0jL6G69duwrx3Bz2oT7VUQ3Ju16j9u+u8Y6gefsRwHtvfaoPPko4R3nxU9SrA6pjHRZQA6aUDJZkqCkvrKAv9wev/QDi6jiOra6I99X8HObRf+dt1ICTHr5fgV6f0Nh58zrm2S9RfeCJOs4lznBtRljE9vb6eL4cF1jeI/oFLIQQQuSAJmAhhBAiBzQBCyGEEDkwVA243+vZ1SuX7saDPtazLZN+1uqjpvrUh89AXJklXYLSdRZLuL1ICUzfegd1hcYi1lYN33ce4kWq+dhYR89mvY5eswXyYEbk281YsyXJKAhw/+UV9BVHMX5/OtZCH3SxhO/Pmi3DeuF+PaKjmAt6mxYXoQ4+VUc/3wRptiWqMc3nJE2wD/dIe3r3MvaZ1TWqY7qKcbeLr+ea2BH7eLd5uRFu7259QBwd4Qifau43EbWV+1mJNM5iQmMZjV0ZacxXlq9AHJRxbAomcPDOaGYqHSM/e5ten9ILKCeB72ADb7yLmnCzimN3tUrrfwLUpJvko3bhwda/6BewEEIIkQOagIUQQogc0AQshBBC5MBQNeBer2sXL27mS97mi+UH9yXy3aYnIW630RMZU03J9SbqadffRT3u3bfQcxlG+By/SrmaewN87l+MUVP+xV/4FMRj9UmIr13D2qTdDvp613uoKbcpH6lRfd8u1R9urGNe4gnySXu/c7Jm1guDYJ95g0dQ8+r3B3b15mZd57PnUPMtk883ppy3KQnzrSauE1iYRx/vyjLWnO7TOoeM+zj5eLdZqblkNW3e7ZxvrwGd7bhdHA3OnBX44o0SdNk597M5ymPdJ/85+dmrlGc/7uFnTwa4/8DhfZV0KJfzDN6XY6cwLlJu5u465Tjo451ybhbrcLsUxzbOsb64hHMFpeW31gDbW6xTgeQ9ol/AQgghRA5oAhZCCCFyQBOwEEIIkQPDrQccBFbY4vWtUM1GRwJYXCcfL+XjzHr4/aE/QB3grR9fgfiH30Pfb7uFGmq1ip7P1XXU+yg9qv3w5bcgPjF7HuLP/g//FOLvfve7EL/88ssQJ6QrWIr6YdLHy5VmnJCVfLykGe+m9j2KtWGDwFm5tKlPVckb3etg3dGb6+j3a7dwe4viXofqhqZ4TdhvuWu6bNbm6BqyZrzt5btcZOdY19+lPeJAeO9tMBjBAtkbZLQWIKG8+WXKlRwWaL0Ovb5A2/tdHFuDALdTSgRLKG922MS4WMOxOR7HA7gqHZCTLJDRubeG9+1CC+/7xiqup2FJPCUNu5spF7QQQgjx0KAJWAghhMiBXSdg51zJOfcd59wrzrnXnXP/duPvTzrnvu2ce9s59x+dc4XdjiXEXlG/E8NGfU4Mm71owD0z+7T3vumci83sH5xzf2Vm/9rMft97/zXn3B+a2RfM7N/vdKAgCKxc2fRhBpRvlL8O9Pv4nP3iW5cg7nYw9/Hk1BTEb5MGfOvmPMQZedO8oSZdoxqRCwv4+nmKv/Pd70DMPtqzZ7F+cKeLmu8PLqCHNKmiztLvkcZLJ6xQQJ1km+93n3rfbrmhWT88Yg35yPrd1naxJss+WK6ZnFLM23fPr43x9r35nPkdtx41j6LufwiOrM95M+vv4rvPE8/9jPpBTHWvq2XMlewyHHtSjzkSej0c20pFfH1APlyfYs6FtI3nrtFdxdd38DtQeYKOTzkhrs9jzockofu4iCJvGOP5SBzuHxaw/UF8MD/9rr+A/R3eU6Tjjf+8mX3azP7Txt+/amafO1ALhLgH6ndi2KjPiWGzJw3YORc65142s3kze8nM3jGzVe/9e0vnrpvZ6fu89ovOuQvOuQudbu9euwhxTw7a77b2uQGtrhRiJ45qrEuz9F67CAHsaQL23qfe+4+Z2Rkz+6SZfeBeu93ntS9675/33j9fptJuQuzEQfvd1j7H6U6F2ImjGuvCYITTUIqRYV8+YO/9qnPub83sZ8xswjkXbXwzPGNmN3d88Z3XW5pufjPcrini94GMntOvLaMvt0f5Q0+exG+d87dw/9Vl3D8ijbZWRx2i3UIf7ttvXYSYvW+rq+gl++bfvARxuYz5QvnXWaOJ3rNabRziwLB961SPuFIhHYXOH6VP3bVWLMfb9ULWpB+MnnjYfifEfjlsnwuj0OpTE7vtlhs+xbHS99C3W6M8+KUixpx3v+/J/0451eOUxhoajFKqN8yacrePY6NlePwsIZ8x1RvmHA4BLvex4gD3HzSxPQF9kS9UcHtcfEAasHPumHNuYuPfZTP7x2b2hpl9y8z+2cZunzezrx+oBULcA/U7MWzU58Sw2csv4JNm9lXnXGh3Juw/9d7/hXPuR2b2Nefc75rZD8zsjx5gO8Xjh/qdGDbqc2Ko7DoBe+9fNbOP3+Pvl+yORiLEkaN+J4aN+pwYNm6Y9UCdcwtm9q6ZzZjZ4i6754nadzju175z3vtjw2yI+tyR8bC2b+h9zkz97gh5WNu3p3431An47ps6d8F7//zQ33iPqH2HYxTbN4pt2oradzhGtX2j2q73UPsOx2Hbp1zQQgghRA5oAhZCCCFyIK8J+MWc3nevqH2HYxTbN4pt2oradzhGtX2j2q73UPsOx6Hal4sGLIQQQjzu6BG0EEIIkQOagIUQQogcGOoE7Jz7Zefcm865i865F4b53vfDOfdl59y8c+61LX+bcs69tFGA+yXn3GRObTvrnPuWc+6NjQLhvz5i7XsoCpiPWr8b5T630Rb1u8O3caT6nNlo97vHts9574fyn5mFdqe011NmVjCzV8zsg8N6/x3a9Skz+0kze23L3/6dmb2w8e8XzOz/yKltJ83sJzf+XTezt8zsgyPUPmdmtY1/x2b2bbuTvP5PzexXNv7+h2b2v+R4fUeu341yn1O/ezT73Kj3u8e1zw3zA/ysmf31lvi3zey38ziZ92jbeeqUb5rZyS0d482827jRlq+b2WdGsX1mVjGz75vZT9udzDDRva57Du0ayX73sPS5jfao3+2vTSPZ5zba8lD0u8elzw3zEfRpM7u2Jb5vYesRYNZ7f8vMbOP/x3NujznnztudPLXfthFqnztEAfMh8bD0u5G5pltRvzsQD0ufMxuha/oej1OfG+YEfK9isfJA7QHnXM3M/szMfsN7v553e7biD1HAfEio3x0Q9bsDoz53QB63PjfMCfi6mZ3dEo9yMfU559xJM7ON/8/n1RDnXGx3OuQfe+//fNTa9x7e+1Uz+1vbUsB8Y1Pe1/lh6XcjdU3V7w7Fw9LnzEbomj6OfW6YE/B3zeyZjVVjBTP7FTP7xhDffz98w+4U3jbLsQC3c87Zndqjb3jvf2/LplFp38NQwPxh6XcjcU3N1O+OgIelz5mNzjV9PPvckMXrf2J3Vre9Y2b/Jm8xfaNNf2Jmt8xsYHe+uX7BzKbN7Jtm9vbG/6dyatsv2J1HGq+a2csb//2TEWrfT9idAuWvmtlrZva/b/z9KTP7jpldNLP/y8yKOV/jkep3o9zn1O8ezT436v3uce1zSkUphBBC5IAyYQkhhBA5oAlYCCGEyAFNwEIIIUQOaAIWQgghckATsBBCCJEDmoCFEEKIHNAELIQQQuTAoSbgUax5KR591O/EsFGfEw+CAyficM6FdifTy2fsTlaV75rZr3rvf3S/11TrJT81Xds8RoDzf+Aw5qalWQZxlmY7bk8GKcS93gC3J7i9VCpCXKlgHEbYPkc51zNuH7cnSWwnojCEOE3xBHR7fXoFvn+xyLWg8fVpip/X0fkuFku4HZtv5rH9fL52451LNxa998f29SJiv/2uWIx9pVK616bHAsdfsbf9AeHxwFFZAUd/2LadvtMPBthnsgyPz/d4QAcMI7wnIop5e0r39ML88tD7nJlZrVz2U2NjWw+Cx+R6DdtP5I77e59RTOeVrzPFfO/zhchSum4pjp2exjZv/HoaC/3OY2NIY5+LIogP/6x2l/NLccDT4j6nyduLe+t30W477MAnzeyi9/6SmZlz7mtm9lkzu2+nnJqu2b/63z57Ny4WcQAvFKsQJwl+6marA3Gj2ca4hfH87TWI33l7DuKlZSy28dxzT0H8iU88DfHkZBli57HT9Pv4/u02tvf2wgrE3OlnxusQNxo9iN965xbEmcfL99STZyE2hzfR6jp+3jjGienZJ7G4R9TDwcz3sP3vf+6c7Yd/+j/+zrv7esG92Ve/q1RK9ulf+vgRvO3DSVDEkSuiey4z7sM40BYLODLFMR0vxDgM8PiLt7HPtJv4JbLfx4G4WMI+OTmF98T08UncPjEO8doqvt8f/P4fD73PmZlNjY3Z//o//093YxfGsN0FO8chTUBhiNchTboQ9+iLzsDRl+NiDcKwgGOZ0Y+D7uoixO3V2xD3uy16OfabVhO39wY4Frbp9dU6XsfysWmI08LOUxWXn9pWjiqgvxTCnUIr9OmLKP8Y2YUvvbi3fneY7xV7qnnpnPuic+6Cc+5Cq9HlzULsl1373dY+x089hDgA+x7rmp0ObxZiG4eZgPdU89J7/6L3/nnv/fPV+uP7KFAcGbv2u619rliM77G7EPti32NdrVy+x0uEQA7zCPphqnkpHh3U78Sw2Xefc85ZFG1++QtCmpAD/DGSBuGOMWu8A3pkPOji08V+hnE2QHksLOEj6YDkNEfPXLc9Eo/wi22f5MH1BSzb6z2+v89Qijh++gTEpTKen7UE9x+QdBLQVBawxM0aNb2ev2MNbJ/PnA/IYX4BP0w1L8Wjg/qdGDbqc+KBcOBfwN77xDn3a2b212YWmtmXvfevH1nLhLgH6ndi2KjPiQfFYR5Bm/f+L83sL4+oLULsCfU7MWzU58SD4FATsBBCiHvhLduiIzo2lpJ9KyUjap800pQ00IxsSP0UNdhWaxX3D1DTLFQmII4jtICGHtuXsQ3IY86BuIoad6VGNqgU23/qNFoYZ0+jhbJF7oX1NmrIKX2ejHzNIZ1uF+Efwoz85bi7kY15m3/9qFAqSiGEECIHNAELIYQQOaAJWAghhMgBacBCCHHEZN5bv7+p04Yp7UAiZUI+3xalteU4zTBNbb9H+zcxJWdKGnGh24S4WkMfbiVGTdhRKseUjLYZ5XK2GDXiSgVTTUYx+ojffOMNiNuUEjUoo6Yc1DBF6YB9v5zrmdLwRzGKvDGnqsw497Y9EPQLWAghhMgBTcBCCCFEDmgCFkIIIXJgyBqwg8KL/Fg9oXq17MXi5/DeuDYpxaRTxKQ7xKRTcC1Sv6v3i+sBc/3dnWt2bivVuu3z4PaY6hF7R1420mEC+vylApV/LODnL1JNLj/Y2Wu3W21ZIR5XsjS1ZmOz/GcQcnUk1GAHVM5vvYulVNc7DYiTjGqbU63uAWnCWYLl/7qksWYZTgVZGX27MeV+djS2ra9he5tNbG/tGOaeXlklnzJp5CePYznCUr2Cr+/i513ooCaehJQbmuaShGu301AW7JIr+qjQCCqEEELkgCZgIYQQIgc0AQshhBA5MFwN2Dlz8Wadx9YAn+N31lFHSNk7RzUr+7TdBaRxFlF3OHka85VWq6iLFEkT7nVRVwgy1CGMNN9GA3WXlXXUebp9/Lx18rbxxSjS16Nzp6YgLhTw80xNYX7XUnGMjognrFrD+OzsJMTXL6NO0/B4PkPyCgoh7pD5zNqdzfEgIJ+po1zL3uO9GPRQQ41IE97qMTYzy1jTTFHj5VzM3qMmPSisQ9ynesBGGrDR4etVHDvPTD+F8akZiJtN0qTb2L6xOo4tKZ0fF+HYudSj80PnI3S8XgfH4pByc2e8Qkk+YCGEEOLRQROwEEIIkQOagIUQQogcGKoGnKaZLa9t6iLrLdQBSBK2xjpuDx02t1goQUzWOBugrGBJgrpAt4M6imVccxM1VRugELC+irpDp4Wvb1Lcpvcrky+52cP9I6rBOTuF+VTDCLeXS6hRuxTjgBKiTtRR465XcHuhjMdPOqi7tNMH440T4mHHe2+DZFO3DOlW2R7j2FIiz78rUs6CFO/VHsUFWi/jXUwxbi+QxlmK8d6vlXEsqZVwPUhAC3aeffI0xKdOoq/39dcp93NnCY8/getRpsZxPctKEzXsJmnq19dRQ9+WinuXHBKWsAasesBCCCHEI4MmYCGEECIHNAELIYQQOTBUDThJUltc2PSbrXfwOb4LUOfodCiXMnnZKqSTzN1cgHhtFX257DVbXlqG+Pz5s3h80jmsh+1pLaLO0B6gptpqoOabkPesSLmZKxPo801I12nT5++1USOf8KjTnD52DuLQSOPObmB7W6Rpd7lmKXkXI5WTFuJeOBdYGG2uUXEeF6i4AO/tOODcw7R+I8LtIflgB108fprg8VPKFe1o/UyBcgaUY1xvUqOcAwVDTfnqjXchHh/D9p86g/WGQxr7fnzlEsTX5nAsf/+5J7E9lEPhFOWKbg9wbmlRzoaQfns60rCzLvmmyVd8VOgXsBBCCJEDmoCFEEKIHNAELIQQQuTAUEW8IAitVtrUFppt8uW2UadYWkCNddDB5/IF8qGOldG3e/I8aqBXrlyGuLmMmifndt6WDrSP7R2soc4QkCZaCFCXKFKNymLE9XnrEJeonu/iwm2M5zB/q2vj648VSCOuoW4zVkKdxzdRsx4sYy7rjDTh3hLmihZC3MGZs8KW+51zD7OD3lEu4jjiPPG4PiYMMY5CXH9i23JD4/GDCF9PKQ6svbYCcW8d18tE9AlCSg596e2LEJfx7YyGNvvQc89AnFDefEqZYMUaatjlCuaO7tAbzK9QnQFKEjEY4NjX6+LY6RNpwEIIIcQjgyZgIYQQIgc0AQshhBA5MFQNuF6t26c++am78X975RXY/v2Xfwjx8jw+t3f0HH62hr7ZX/ypT0H8/Cd+BuJv/s1fQ/yf5/8zxAkVGOZ4m283xLhL+8fklatXUbeYKKDPuJTh8bI+fj9KF8mXO4fno7mMus3COuowSRUv96qhht1poO5x4xqe/14fdZPk3Xds1HFBYIViZfcdH1HiEvbBcpX67ACvuXm8xpQy2AYD8ktmePzAsE8mCe6f0j3Myy6iIh5vfArv8bFJzBHMdVs5x3F+eDgXgz5qtGlKmq1HTTWKsc+GIZ4XtqV6ylXMv6xSGksGlHi/18OxgH3DZRr7JqYxtzP3s/oErsep1dBn7Kje8LknKAfEGq4/KZXItzyG6124PvAk5bXvraPGy3n5HWvCVG85TTib9NGgX8BCCCFEDmgCFkIIIXJg1wnYOfdl59y8c+61LX+bcs695Jx7e+P/kzsdQ4j9on4nho36nBg2e9GAv2Jmf2Bm/2HL314ws29677/knHthI/6t3Q6UJqk1lje9q7Ejb5tRvtMMdZF6CXWEExPHIZ4iX2vQRR1gqoya6wfOPw1xh3IlB6SzUDldqxXQe5aQbtJcRZ9ut41xo4feuW6Euas7TTze6o15iNN10nAzfP21i9cgnqPPZwPS68gM6BL8flagoqHry3RCjpav2BH0uzCMbGxyeqddHmliqusahqTjJ6h1RSFqwpyPvNWmGtqe1kWUUbONI9QGBxHe0yVaFzE9g9dqYhrnu1IFcxK3qO4r1/zeJ1+xIxrrfJZZd0u9c86z3qPzXqf6vYUSacKUQyClvOztLmrKWYJxgYZ61jQjw+sceDyPZVqvwkZmVkh7GbavSTkEZmexn7TblFd/Dfvh2grmHChTA6ZnURNO+zi2RqSxxzS3JBRHAZ4vx8blI2LXo3rv/97MlunPnzWzr278+6tm9rkjbpd4zFG/E8NGfU4Mm4NO67Pe+1tmZhv/P36/HZ1zX3TOXXDOXWisN++3mxB7YU/9bmuf69JqRyH2yYHGunavf7/dhLjLA1+E5b1/0Xv/vPf++fpYbfcXCHFItva5Urm0+wuEOAK29rtKsbD7C8Rjz0F9wHPOuZPe+1vOuZNmNr/rK8xskAxsfmFu8yC3r8P2Rguf8585gV82P3LqWdxeRK/ZONXfXX35NYifoC+lk899COLr61iD0tYpN/Uitq+7ihqsp/rG1ZuYuznoogbco68/CeWO9pTreoo024BqiIaOTJWGOpAjpcZ59kxSvtgY44x6S8rJsh88B+h33tLswXj4HgaSNvsb0SveH+AT18TjPURSo7Va+BQrzbCPlUp4T05MzUBcw2UTFlNd2vFpXOfhyZfcWsN1Dts04Dbeg0fAgca6NE1tvbmp+/baeN4GGWqUhQK2ezDA7SFp6X3avryC1zUjjblawHu9XMTzzr/ECuT75evUpHq5PPRUZ/BCU5p/69HYE5dRw508hi269OaPIa7gch8z0v7rdfyxt7yMY3eS0lhKubXLZWyffzCpoA/8C/gbZvb5jX9/3sy+fjTNEWJH1O/EsFGfEw+MvdiQ/sTM/quZPeecu+6c+4KZfcnMPuOce9vMPrMRC3FkqN+JYaM+J4bNro+gvfe/ep9Nv3TEbRHiLup3Ytioz4lhM9Rc0HEc2+yJ2btxJ0PdIyrjg/azE6cgPpHig//+DXyuf/Xy9yFOG6i7hKSbtEmXWSI9q0Wew26GukBGeXEnSQiZ7uLnqSao43hP2iQZjbfne80oxs8zCChXNOVbTShPL9coDeiBiC9gXDmGHs36JAsxu/DtV/e3/xGQJANbXr419PcdFQY97NM+RQ11MMB1CQn3iRj7fIfEvLCIWmEYo5Y2PoF9JHaU75w6eeDwnmixttlHf2iQYHtIYs6NzLz1tui8ju6lMp2HIENNtUvrUfptPK+9BPePqBa5RbieZEDHT6neLucAmCH/dUYadEya6dknMadCQO/fy1CT7lIu6hnKHV0ew7Hm0iXMaVAo4loBC7B9ber3ay3q5+RvLxVxrA9jXH/DubaPCqWiFEIIIXJAE7AQQgiRA5qAhRBCiBwYqgYcBKFVa5vP+j/y3Ptg+9PnjkGcNlC3aF/D5/jtGDXkZUNPYGsdfbhjlO8z7ZFG6nB7g3JJtyj/aI+y3QRkvq9V0dvW7lJ9X9LbEpIZWAPeRkiadITHT0iTpo/PJUgtJB2pUEEvXUQ1QEsT+PlGEee8hcHjm5Wo2cN1Ep60rx7l6OUETqyFhZT/fKyOWuEE1estlvGe6LdQm+vQOo10gBp1MsDtdcpHTiWurVYc6pB2X5xzFm3Rw8OAfLVUtzggjXFAGm1AY0WR6ianlHs5o5u7WsOcCiWqke3p9RW690sV9AFzfvV2lzTePl7H0+fPYPso0X5APmNHmu7Tz30Y338c1xZkNDY3ruC6j3YHz3exiK+PqE62Jbi+xnPh6iNCv4CFEEKIHNAELIQQQuSAJmAhhBAiB4arAbsQ/FvdJtbInL+Bz+0btzFPbS1A79fYmVmI2ykKWJ50iWAVPYRpG/WoPomwy33cXqH3C/qke5COU5k9CXFnAdPIDsjLl1JuZ/ZIJinlcg5JUzak3cfj91LUNfqkBw7Im2d91N9qXXz9+CJ6NEcW9/h+z2TlKiPt0ZGfs0Cab20MtcJCDV/P9XonarguIGmhFrg6h/5WR1pbSF78KMV7rERDVoHWScQOj5cXURjazJb1LiFpnGlKnn3KKZDR53aOYurS1Spep5TGjulp1IArFbxOnvYvUq7okHJJLy7PQXxrbhHiD3zwoxBHVJeaf/pxfeM+adhnnkafMfuel5dpfRClBI8L6DOujOPnL1HNljjlXNfSgIUQQohHBk3AQgghRA5oAhZCCCFyYKgasHOhxeGmjpvGqB+dPfMcxMsefbydVdSHuinqEu0BfZ9wmN8zTfH1XAA8S1IAACAASURBVDMzjtALViEfb3FiCmJK72p9ylv7zgpq3Bn5itfJA9kmTbg34FquqG+xzpNQ3CNNd8C+Y/IJpwF+IBdi9zh7DHWksIxewVEk884Gabz7jo8otQm8ZlFEheIzPDdlyuU8Non3kBWwD1YpX3rM6wi6eM+drFPOXxqBmis3IO5QLgDfxvdPKP95q/WACrfulyy1rLOpS/Y7uP6E15skVPu7P8CxaUB+6IS08+njWHd59iSuPwlJY7159V1sL40F5TKKon5bTgFs71NPoM93mnIEdKmO9OQ0jaWkERco93RIOcmNxqrllSWIB1083+wPr5dorK/g8QuefMHSgIUQQohHB03AQgghRA5oAhZCCCFyYKgacJZm1l3d1DbKFdSAT548B/HlJuoAl+YuQ9xu4HP+9gJ6DksDfK7vE4opv2dEPtyQNOH5RfQldxPUt0KqTXqFvHF90nwz9uFSfWD2ATvSXQLyAdNmS8kFSuqcJZzfNKQDkNmwRUbj1cGD0UWOkiiMbHxievcdH1HGye9YLqNfNAhQ8y2R37NYpj7QodzSXbzn6jHuP/vUkxCnbewzCzevQJy08Z52VMOb67JyTmFjv2lOpIO+rS1s6qx9z559HNsGVGuc12+0yU/d6mC8Rjm2zfC6FklCrVKO7tlZvEcizitP571EPuL6OL5+QNfRKFdzmccaWv/CmnNMubR7Pfz88zevQtxtod+8RGsfAqrVXiphbuhiAd/PUfuPCv0CFkIIIXJAE7AQQgiRA5qAhRBCiBwYqmDSXFu3f/jLv7obT9TRQ/jxDz0D8eq16xBf+u7LELdJ9+i3UHc4XsHapWGCCUITijtt1AVWe+QxrKN+1vNUPJV0Gx+h8JKSty1J8f1SjzErrKxCRKQBh2yDzki0Jd3FUb5V1l34DbMAu0sSUwLVEcQFgRWLxd13fEQplbDPco5fjgslvMarq+ivnLuJ2lqR7qFzzzwB8VgJO+XFy9cgvnEN13VYiuskKiW8ZybGUMurVjGOwtHwfGdZat3WZh6AkLX3iItzUz1g8uw3KCfAagfP+1IHt5ermDf/J96PuZQLDo+/uoTXldeXVGro+e/SWBWSLzdxeB3GJnC9T7dLuZu7OFaO1VFj7nXw+O9eQR/zjUsXIQ7o+AWyv/tV7GddR7mfx9CvHlDt9aNCv4CFEEKIHNAELIQQQuSAJmAhhBAiB4aqAUfObLaw+ZbPzmJ93XgBfbPrP/4xxAXSKUrk2/UhegYLGeoAfdKXzNBLFoXsiUQdw5OWGFFNzw7nXiZdh710nkTWkIy8ZAPe7oGk93OOKwLj9oA1XfIhb9OYi+QzpgMMRiTt7k4EQWDVWnX3HR9RSlzolGi2GhD31zAH8c2bNyFeo3q+JyiHbmMR87evXEPN9/o1fH2W4bqN06dQu5yZRH/meI38mQHXzLbRwOH9wrmV4wp+rsSTb7dHdY0j9hHzWIJDeamCmu3tBcxhUDRcPzNRp7UBZTzPIdXfDWgsGBvD9wsKqHlz7uY+adqlKp6PgPLQ37yBOcJ/9NprELfWcawfL7LvmLIgZDj2d1vobx+QRs61148K/QIWQgghckATsBBCCJEDmoCFEEKIHBiqBhwHgZ0obWodt3/0OmxfePcSxI3FOYhLJFIWK6hTpKQHdalmZkq6B9eYrJBOUyDdZZ1qdDrywlVJM+6SD3ebJkw+YAtxuwuznTZbOcbPXyxSvtMQ3z8o4OWOYmxvRLmfwwh92q6McWSjIrjdnygKbYZqjz5OBOTd7pB/dG0Na1jP0zqLXhv3L5EWFtM9sHADNeO0j/cM21/rY9i+UydRAx6vo36fUk3sPq+DoHUcueGdpdnmZ6sU8XNMUn5yF6FmOiAx+3gdNdZTY6iZNiklgfH6DLq3x8bR5+oMz2uRfMsRjW2FEo4FPapvPGiRD5fGpgr5gkOH/WDhNq4HeuctXA+0toyabY36Sb3CubCxn2Q8NlMOhGSAGrElygUthBBCPDJoAhZCCCFyYNcJ2Dl31jn3LefcG865151zv77x9ynn3EvOubc3/j+527GE2Cvqd2LYqM+JYbMXDTgxs9/03n/fOVc3s+85514ys39pZt/03n/JOfeCmb1gZr+104ECM6ts8e5GpEPMe9JQO6hLxDFpjvRc3pN3zAI8XkrP/dM+6QCkEadj+PpiDbXEKEUNuUA+3Mo06llZFT9vQrmmDWUe8x51CE/ewDhE3YM9n8UiacARCkNBiBpykOH5TLv4fqxLOWrfEXMk/c45Z3E8GvmB86DXY+1r5xrTJfK6l8jvWeM6s1301neaqPkWSfStV1A7LBYp/zndow3ydzqqmxsVeB0E3UT74+jGujCyyvixzXZVceyojs1AHMV4XrIUz8N4FTXZKYpvr6Cfe7nLeeXxOqys43WbHudc1ZQDge79dguvc4PqRMe09qBG61+sif7va9dx7cF1qgPQbeLn4zz4EdeBJt9yYthv+pQjwZOvOqS1DQ9GAd7DL2Dv/S3v/fc3/t0wszfM7LSZfdbMvrqx21fN7HMPqI3iMUT9Tgwb9TkxbPalATvnzpvZx83s22Y2672/ZXan45rZ8fu85ovOuQvOuQvr7Qf6i0k8ouy3323tc62m+pzYP4cd6zqD0XcIiPzZ8wTsnKuZ2Z+Z2W9479d32/89vPcveu+f994/P1ap7P4CIbZwkH63tc9Va+pzYn8cxVhXjh9M+TrxaLEnH7BzLrY7HfKPvfd/vvHnOefcSe/9LefcSTOb3+043gXWjzZ1ytU2mte6EWqYA/KGuT5qtEZ5ZFnz5dh36VspaaqZkX4VooZbGMfY4+5W83i801XKn2r4edMG6hChp/bR16NWgMdfa5KO0cDzUSmhrsH5X8OEdA7WgClXdML1hR8wR9XvjOscP0b0B3jN223Oh47XdGYc/aXs5ywmpCm3aZ0ArauIaF2HK+DEFFP93n6P+iRph1Xyn5bL2N765OE830fV50rVmn3gEz+3+YeA86rj2DCgvPJphuc1CLj+LmqifoBxt4VjTUL1hckma0tU27xHuZqnKjg2ZyFeh5aj9SlF/Hwt6ndzP3oL4vlF7Gch5fmvUW5qnrnW1nHsazdxLItCbH8SUE4Dyv1cifHzcx79o2Ivq6Cdmf2Rmb3hvf+9LZu+YWaf3/j3583s60ffPPG4on4nho36nBg2e/kF/PNm9i/M7IfOuZc3/vY7ZvYlM/tT59wXzOyqmf3zB9NE8ZiifieGjfqcGCq7TsDe+3+w+6/C/qWjbY4Qd1C/E8NGfU4Mm6Hmgp5fXrE/+Np/uht3yVs2Td6uE6TdoYvWthWkdQHlI83wOX5GeWQj0jQL9PqAvHhra1Q7lfSvjDyRkymKxGXSz+KMcjOTDtRy+Pmuk8Z7ZYnWh1C+1zPjqHM8M4bxBOlrjs5HQu+f8cKSB1Qj8yjxPrNej3XPx4dGcw3i1eUliPmSlmLUynyX1w3gPeWTnWtOD2j7oI+vj+rkP6X5L2C/J+UkLlN+8onx0cj7nXmz5pbxiVMJD/qYY7vbwbEioRzalYDGKspLz9o++6mLBVy/ktB1XFzAsWQFUzFbt1aHeHLmDMSNAX6eRhfHqqkq9qv1ZeyXnRb2k3IV/dwp5c3PuB+m6Hbo0LKPmOoDh2U6PmnkRuuNgm211o+G0R9BhRBCiEcQTcBCCCFEDmgCFkIIIXJgqBpwuz+w77+7WS80JW/cCa45OYm6QZW8ZRnl68xIP8pCyv9JBXWLpHHGVP+3SjUx0wrqBktNrKXqeqgbTJG3rEpeuww/nvXJ+3aL8qW+3sN8q/NUIDmk9rfIJ10mXaRSQjNgSO1P6HzVjqO+NjGDNU135dXX9rf/keBte3HUx4eA+zitc6hG2OdcF7W8Iq2DoLKq5hy+vkh+0YQ04CjG948jjAskSoch+TljjIvUhwuF0cj7naSJLa0t341Th+3KaL0Hn6eUNN7KGPpg6xMnID5DeeCnU1yfUh/He7VIuZPTPmqozVXUaLM++b9Jg61TP0q5VngXjz9FCXJ6CW4fpD2K8XyVae0Crx3gucF5Wn9DY3OR5paQ8vwb57I+IvQLWAghhMgBTcBCCCFEDmgCFkIIIXJgqBqwC0IL6ptu3gF51ZqUC3mFchXXC/icv0/esA7pHgOK2Rs3TbVKa1yykjyQrRD1sT7pNqwTRPR5yvR+bgx1m0V6/Y1l1EVuUw3L/hh68wLSvBd6+P43yBd9nHJlj8X4fcxzLuoBns+0+ZD4a/3jqwFXi6iRRhWsIV0lqWswoBrUtE7Db9PCsE/H9H4h+XiLJNGG5K8kKc7iEr4gJg24VKb3ix5Q0t594sws2qJfp+Qr7VJluCzD81qiE+Wo1nmLchqU65glocj5zx1p5UX0T1dJI56aRI3ZyLfcaWNOhBXKGV6boFrqlIs57eN1GqvhPdrroQYe0joOR3UDeK2Ao/a6BOPyANs7UcKx1GLU3L1/MFOlfgELIYQQOaAJWAghhMgBTcBCCCFEDgxVAw7jyKaOHbsbr7XRp5p0SFdgDbeBGuatNfSqrZMmnHrSiwr4XP/Z4zMQn6uijlKfQR0koO1rTdQVepSLuUO6TZG8Z4MW6hxrVJ940MHPU3Go2xyfOA5xHKPu0llcgLjfJm8dab5hhPpgRrm6uyvYvgblFR5FsjSzXqu9+46PKJ7ypRdJw61TPd4WJXPu0LqJgDThgLzrnI+8SFom18TOqF5x6NAfyl71AuV+Zq3Uc07fnHBBYOXK5ngTsYGa1mPweXUUt+jebdJ14ZzexYj90Pj+c7eXIQ7Jxxs47AflgMdS+u3mUJPttDFnQRLi542p1vtYEd8/Iw02o/UqWYz9wDivPmnCRcOxqxbi+atwrmc6H5787keFfgELIYQQOaAJWAghhMgBTcBCCCFEDgxVAw6cA02nPo6a48oi6lWNBmqMPsPtTcqv2iLPYUbfL4IKer1KTzwN8clnnoM4nERv3Bodr1LFGpvFdWxvb+4KxKsd1CIT8v6tD1Cn6SWoO5QC1EVKKAtZQN5AT5pxjzTyhqFuM0a5rtmbmJDulD2g/KhHic8y67a7u+/4iNJv4TqLOml5lRr2kYTuoS55qCsV3J/K+5oFuH+pSPcg5RT2xhozHq5Ywj5fKGLcIC961sB1GXnhAmfRFk90FKOWXapSHWS6LiFp846G6oA1SlovszI3Ty3C89ymesOddVofklDefHq/agnbUyng9rESjo2lAu7vMmxvHFBuapJkW7SWIaT6wj7A82kp9tNihp+v4CkHOuXGNpZ82Vd9ROgXsBBCCJEDmoCFEEKIHNAELIQQQuTAUDVg7zNLttQb7bTQK5aRh6/HaV1ZkwxQV/H0XL9Mmu/s2TMQn3z2gxAfe+YZfH/SONukN00dw/q45SnUtMvjpPv0SDBjbxl5IsuXrkKcLWL+0vrMJMQR6XfvXr+Fh6+Rz/fcWWzf+ScgrtTx/EXka85YqNmN7/1/+9v/CEjT1NZWVnff8VFlgH1uYpzyh7PmSlpdgbS/ifFxPHyCWlurh5pzRPV+2a9ZqqCmG5CX3VOu6fUmrqNoNLAmd5qMyroEZ+mW+7ufUl3kiDRR8t0WCqhpRhGOJQF5+Pk6NRs4VnWamGPBs6ZJGmhMPt8u5VJmDbdEuZ6nJimnAo09CeV6Nlrfk3j8vCn5oLf5dOn8DBL2VZOvmETePt8IIY9t0oCFEEKIRwZNwEIIIUQOaAIWQgghcmC49YDNbGvJ2jY9109JJyHLoHXYC0a1R08fn4X4Z3/u5yH+uV/8BYinpqiGJmmoV66hBrt+4yLEZ06gpvwLP0PHJ69cRD5cR963JskMhb/7fyD+xv/9XyBeamAubM6D2/eo05x58jzEz/zsT0P8xBn8PGfP4f41qiW7vTbsLvy7393f/kdAmqbWoJzhjxO1MmpzXD83pRzBJLluu8aco7hYwuNntKyhWsI/JG3KTV2hfOSUA7jRRu2x2cI+3aN86b0uG5PzIckyW25vtqXX6+2wt1lI6ytWu/g5Q8q5HdBYxTkS1puoxQeUFz8tUH1ej+eN/dYR5SRIqD5vh+rzvkO1zMNV/PysecesiQeUN58lWcqZkNLYN0jo/NH7FUkzZk189iTOJexHPyr0C1gIIYTIAU3AQgghRA5oAhZCCCFyYLi5oIMANCgXoKewRXlr26T/pA6f2z/7FPp2f/m//+8gfv75n4L45MmT1CLUMTzXPqWamhHlZ41JR+j28Xg3SPdJEtItuH5xijpEr4vtiej7Uofq9UYh5Y6OKDd2H9uzuIQeSmqeNUhv26bTuIfh+5u3LNunX/kRIiD/YqWEfbhcIU24j+fKUR9vD/B4EfWxAmmL1Rr1mQr2ea6L2yaxb72BY0K/h+9fpvcrcGFcIUaYh2EEFUIIIR45NAELIYQQObDrBOycKznnvuOce8U597pz7t9u/P1J59y3nXNvO+f+o3P0fFiIQ6B+J4aN+pwYNnvRgHtm9mnvfdM5F5vZPzjn/srM/rWZ/b73/mvOuT80sy+Y2b/f6UBhGNr4xGb+4g75gLvkfXOUrzMk3+z6Ku7/3f/2BsSv/OAyxJ5qmzrSx1grTDPeH+mS57BNeWr7lIc3Tfn42P6E9LBuF4/XIU28WqXc0+TxXF/DfLC3by1A/NprP4a4UMK8vlzDlL2KnM/2iDmSfpdl3vpUJ/lxYhBgzt2M8o0XyL/puC5tAftARn2At8ch3jNBiPdYdQzXfawuYw3tlcVliNnXG9KYEFN7C+GhcvYe2VgnxF7Y9Rewv8N7I3m88Z83s0+b2X/a+PtXzexzD6SF4rFE/U4MG/U5MWz2pAE750Ln3MtmNm9mL5nZO2a26r1/b93sdTM7fZ/XftE5d8E5d4F/EQqxEwftd9DnOJ2aEDtwVGNdp7tz5ishzPY4AXvvU+/9x8zsjJl90sw+cK/d7vPaF733z3vvny/Ekk7E3jlov4M+Vxiq00485BzVWFd+QKkLxaPFvkYn7/2qc+5vzexnzGzCORdtfDM8Y2Y3d32zKLKZmZm78d996/+F7X3K7xmS79ZRc5eoPu7iwisQB5S3NqQakmG4reDwvRu+pQWwN9Un9mQ35XynzOaX6jukxrmxBxRT/tU26mfcAH57Ph+evn8NyIecOMq9TecnsuH4aw/T77LUW2Otu9MujzQlukQDqkmdkpe8SLp+qUi6f4ydanJqDN8gwT682limGPv8yiLWah508VpVaV2D0bqJbgf3T47o+9Zhxzoh9sJeVkEfc85NbPy7bGb/2MzeMLNvmdk/29jt82b29QfVSPH4oX4nho36nBg2e/m+eNLMvuqcC+3OhP2n3vu/cM79yMy+5pz7XTP7gZn90QNsp3j8UL8Tw0Z9TgyVXSdg7/2rZvbxe/z9kt3RSIQ4ctTvxLBRnxPDxu27puth3sy5BTN718xmzGxxaG+8f9S+w3G/9p3z3h8bZkPU546Mh7V9Q+9zZup3R8jD2r499buhTsB339S5C97754f+xntE7Tsco9i+UWzTVtS+wzGq7RvVdr2H2nc4Dts+5YIWQgghckATsBBCCJEDeU3AL+b0vntF7Tsco9i+UWzTVtS+wzGq7RvVdr2H2nc4DtW+XDRgIYQQ4nFHj6CFEEKIHNAELIQQQuTAUCdg59wvO+fedM5ddM69MMz3vh/OuS875+adc69t+duUc+6ljQLcLznnJnc6xgNs21nn3Lecc29sFAj/9RFr30NRwHzU+t0o97mNtqjfHb6NI9XnzEa73z22fc57P5T/zCy0O6W9njKzgpm9YmYfHNb779CuT5nZT5rZ/9/e2cbIdV/n/TnzvjP7vlwul0uKtCzVtduqiSE4MWr0Q1IBhb/YBRLA+VCogAEXAQrESD9EboAABYLCyQcXKIrWMBDDKmDYdWqjFooEjuDaDQK0shnFkWUpEimJFF+W5C73bXbeZ+6/H3ZEznOG5OzuDOfe5T4/gOCeuW/n3nvu/c+d555zXu/57I8BvND9+wUAfxSTb8sAPt79ewrA2wA+liD/DMBk9+8sgFewV7z+OwA+1/38qwB+O8bzm7i4S3LMKe4ez5hLetwd15gb5w58EsAPeuwvAfhSHAfzPr6dd0H5FoDlnsB4K24fu758H8BzSfQPQBHAqwB+BXuVYTL3O+8x+JXIuDsqMdf1R3F3MJ8SGXNdX45E3B2XmBvnT9ArAK722A9sbJ0AlkIIqwDQ/f9kzP7AzM5jr07tK0iQfzZEA/MxcVTiLjHntBfF3aE4KjEHJOicfsBxirlxDsD3a46rHKh9YGaTAL4L4IshhJ1B84+TMEQD8zGhuDskirtDo5g7JMct5sY5AF8DcLbHTnJj61tmtgwA3f9vx+WImWWxF5DfDCF8L2n+fUAIYQvAj9HTwLw7Ke7zfFTiLlHnVHE3FEcl5oAEndPjGHPjHIB/CuDp7ltjOQCfA/DSGLd/EF7CXuNtIMYG3GZm2Os9+mYI4Ss9k5Li31FoYH5U4i4R5xRQ3I2AoxJzQHLO6fGMuTGL15/G3ttt7wD4/bjF9K5P3wKwCqCFvW+unwewAOCHAC52/5+PybdPYe8njdcA/Kz779MJ8u8Z7DUofw3A6wD+oPv5kwB+AuASgD8FkI/5HCcq7pIcc4q7xzPmkh53xzXmVIpSCCGEiAFVwhJCCCFiQAOwEEIIEQMagIUQQogY0AAshBBCxIAGYCGEECIGNAALIYQQMaABWAghhIgBDcBCCCFEDAw1ACex6bR4/FHciXGjmBOPgkNXwjKzNPZKrT2HvbJmPwXwWyGENx60zPTMfFhcutetyW+74+2I7XwmzSt08w/aE3M9SlLOTqd5/b6lSRQit302Ox3nzwCHwgCPH7caZZffeWM9hLA4zDoOGncnTpwI58+fH2aTxFGrHOf9NR/VwZsH27+Dzt+3/IDjedDj7ef/+c9/PvaYA4BSaSLMz07fW4e/V0V8L0mn+FnI73Wr1fJe8fJpXj7tb15u+61Wk9fmtp/JZMh2t2Kk3b3Yn6ZWp8PLu/01dzP2cRm5Fab88fHHc4B/4+b66tq+4i4zaIaH8AkAl0II7wKAmX0bwGcAPDAoF5dW8B/+0/+8a4eIT9JOo0b2Zp1P2pPz02QHd5I7fSeZt5/J8Fkq5Hn63NQMz5/i+euNBtntJm9gt1zn6W0y+4KkHdj/trvsovs1NTvCPP8vnrkygtUcKO7Onz+PCxcuHHpjfV8SXcwNmv9RD9iDthfcndM6Lqj6vlNGzvZfknl65Obv+5I6gEHH19t+fn9j9/OfO3du7DEHAPOz0/jdf/25u3Y64ptBu7JL9kxxkuyWO443b3MTIHM/Xk6XSmRP5t0A1OJ70+qNa2RPlIpkzy4skN10cTQ1y/fKlgvzmxvbZFdrfG/P5vjmmzL2t9ngLxzFST4+tTrvjwsDTM3OIk6+9If/ZV9xN8xP0PtqOm1mXzCzC2Z2YWd7Y4jNCQFgH3HXG3Nra2tjdU48lhz4Xlep1PxkIfoYZgDeV9PpEMLXQgjPhhCenZ6ZH2JzQgDYR9z1xtzi4lC/PgoBHOJeVypNjMEtcdQZ5ifoo9R0Wjw+KO7EuDl4zIUAdO7prObeL6nUWYPd3r5FdirPA3iqwPJbLsXr2y3zT76tHZbL8mn+jbaQz5K9MM8PR6fPniX75to62evrbAfnT6fDP7mbe9Qz9xN7q8HHI7j3aRbm5si+cv0m2RubW2RPzp7AUWCYJ+Cj1HRaPD4o7sS4UcyJR8Khn4BDCG0z+zcAfgAgDeDrIYRfjMwzIe6D4k6MG8WceFQM8xM0Qgh/BuDPRuSLEPtCcSfGjWJOPAqGGoCFEEL002o0cP299+7apSnWMEPb5bk6NdCcpurTrRot1nhrFdaAKzW2lxc5Lef8E6zxpnKsOV+69C7Z19c5myCV5aFj1mm0BTc94/J4zYnCzarLcw783tv25ibZ1Sq/ZV5yKaTzJ07y+u77Hl38qBSlEEIIEQMagIUQQogY0AAshBBCxIA0YCGEGDFRp4PG1r3c1FKe83iL+QLZpUKO7O06a5w7Oy7PNc+37rOnueBMzliTnZ/h7W9vsUZ8+9oq2U2n0RaneHmkXYlTYzvt7AlX97fiNFzzdU1cHeHtbadxu+VPLbDmu3SaNe6koidgIYQQIgY0AAshhBAxoAFYCCGEiAFpwEIIMWJymTRWTvTosK4V6kSW83qnJvlWXHV5v0tLXKv5/MppsvOuAfCN97kb3jvvcfvB3WqF7JDm2tBP/f2Pkt1xmu7V9zlPOOprtp5xJmvAabje6y7vN5Nhf9opttNZtgtFbqeIdLz9gPeLnoCFEEKIGNAALIQQQsSABmAhhBAiBqQBCyHEiMmkU1iYupfrOzEzSdOXnIZbc/1wG6kO2YWJEm/ASa6XL7PGe/HvLpJdr3Pt6LPnOU925dw5N/082T4PuVFhTTrnNNco8NByZ2uH7HbEmnJwz4ItVyvbck7TTfP6804D3tzhvOGkoidgIYQQIgY0AAshhBAxoAFYCCGEiAFpwEIIMWJSZpjqqde8vHyCphemWLN879pVtq/eILvV4bzg3e0y2VmXJ3vq9Blevsn9dvMl1pSXllmT3thkDfXKlcu8PbTJLhS5lnUwHlrM5f1Wa1WycxOskdecv5XdXbe9KV6/65+8vc2ac1LRE7AQQggRAxqAhRBCiBjQACyEEELEgDRgIYQYMZ1OGzvbd+59cJ01yptv/B3Zv3j3fbKbHc6DPbHA/X5npmfJbrg830abNdozZ1fInpufIXu3whrr6q3bZK/f2eD1neL+uw3eHDa3N8lO57gWdLbIGnS5znnQkdN0I9ef+OTCEtnTTkP2Gndf4nRC0BOwEEIIEQMagIUQQogY0AAshBBCxIA0YCGEGDFmgKV6dUfWIBtNrvU8Pct5winXTzfn+t+eOLFAduTyjvdU7wAAHClJREFUhOv1OtkLi1y7ebLEmuyN1ZtkF3Kc1zs3z9srlKbJnijw+mpOE76zwxpz1tW2btV5gYkSa7rTswWyJyd5+qTTlENK/YCFEEII8QA0AAshhBAxoAFYCCGEiAFpwEIIMWIKE0V85JmP37Utyxpmfo5rIS9WOI/XpQGj5monFyYm2C7w+tMpfrbymmkuzZrrqVnOC94us4a8W6mQfWWVa1UvLXBeMIw162aHNfDghp6TK0+QvXxqmexqmTVkr6nn8nk3WRqwEEIIIR6ABmAhhBAiBgYOwGb2dTO7bWav93w2b2Yvm9nF7v9zj9ZNcdxQ3Ilxo5gT42Y/GvA3APxnAP+t57MXAPwwhPBlM3uha//e6N0Tx5hvIIFxZ/bwmrJ+egjhofao/YkizgcN5rbn3e/bHf4g5feHV9+3fN/++c0f8Ph42++fX9+g8zOAb2BEMddod3B57V5PWkvX2M80a6TlCvf37bi83mmn0baarOGub9wh29eGvr3Geb4ri5zHO+n6CUdNt/ztW2RvN3h6Ps/9jetV7ufbaPN5PHWK+xWfeeI82VNO0764w7WzKw3WxK/euM7LT/LxSioDn4BDCH8JYMN9/BkAL3b/fhHAZ0fslzjmKO7EuFHMiXFzWA14KYSwCgDd/08+aEYz+4KZXTCzCzvbPraFOBD7irvemFtbWxurg+Kx41D3unKl/qDZhLjLI38JK4TwtRDCsyGEZ6dn5gcvIMSQ9Mbc4uLi4AWEGAG9cTdVKgxeQBx7DpsHfMvMlkMIq2a2DOD2wCWEGJ7Y4y6Vevh31kEa75Aa5cDtDVp/SDkR1y/vRN20y6f0q287kTc64P4N0nBHrPEehkPFXCsKuNVT37hS5TzW4Prbbm1x/9y2m//DaZ6/WGLNNdS5tnS9wZpzzdVaTkf8hD6V9rWc+bxu73IecNb12207zXq7yhptcY5rXU/P88PYrTusYe9keGhquPXv7rLGXKnwr6utJvcXTiqHfQJ+CcDz3b+fB/D90bgjxENR3Ilxo5gTj4z9pCF9C8D/BfARM7tmZp8H8GUAz5nZRQDPdW0hRobiTowbxZwYNwN/gg4h/NYDJv36iH0R4i6KOzFuFHNi3KgWtBAHwOehekad5zuIvrzfAduPIteo1SX2psCab+Q04citvwO3fZ/4680Beb3e7nRY2/QcdP5xEZBC0+7pqttO0224PNucqxU9NceabMcdyEKe83aru7zfCye4Xkje9fctZfjHz8Y2a7w+zzbllrc029kc16YuzXDcLJw6RXYuz/vbcT/GZt32Tp89R/b0NGvc9foO2ZZKRhwMQqUohRBCiBjQACyEEELEgAZgIYQQIgbGqwEHIN0j2fhf6Ttt1nN8R0cLPieQvz/06U/OTvkUQre+dsvpUa6ObqPO0xsNttu+iacvlOtNvz/OX1/GVySfGPJUH0pf3m6D8z+z7qKwDNsd85ov0x/xD4/5QRr1oLzmR11be1Rk0hnMz9wrAjOR47zdpqvVnHGabDbD+1XMOU11dors0GTNtu9W5M5zYYL9abs84fIdzksuTHHt6Ll5Lgg2v8AFb2ZcvnzLDTVtV8v6qQ8/TXYmw3f/rKtVDfcqw/Ub75F97dolHAX0BCyEEELEgAZgIYQQIgY0AAshhBAxMFYN2MAjvvsZH22nARez/Lt/xqnCwetXXg8yVqxSzrbA3z+aTgfxGrNL3UOz6fUo54/TQQZ92+lzP6H6lhgdfWd4wCk/qMTcbHBN3DXXN3V2irXE0twC2R1XO5or8AKIfC3ph+dJ9+XtDshj9rbP8223+Zr1ecpxEUKEZvOe3p5xtZxzpbyb32m+EzwdTc7Tbbm84kyHj0Ot5jTmAmu+rRbPX2+445jie+3ULOcVT89yLedUioeS2XmOo+L0LNkuLJFxd8d0mteXzTgN2F0HJdf8Ip09Gs+WR8NLIYQQ4jFDA7AQQggRAxqAhRBCiBgYbx6wAdajhQSvB7nZZ12907RLDO5PdWNhwOfWpdO+16nLMXQOeJ3Eq1vmNOhogI7RX3eXcal/iKJk6FlHnQHlmw+4Lq9RPnz+vsz0MKCWdN8GfV4sT+7TUCMO4kadtcPVK1fIbi4ukb1UZK2ubbz+pnew7d+reHgNXq91tp126c+Vz2eNOqxttpqsSielArClUsj36Ly7O9s83Z3pnHvfxZymWt7lPN+wy7WQQ5PtSoWPUx5cW7lW22K7yssvrayQ3cixJu3vjc3AdqnImvPyqdNkb21xXPqaB8HFVbVeJnv9FrdljgL7P+W2n1T0BCyEEELEgAZgIYQQIgY0AAshhBAxMOZ+wEbaRqvF+k3L6QDFvM/94hnSTp8q5Hl3XEtJRB3eXtbpLlGH7d2KS1bztZpTrta007fSLvfPy38Dc0BthOLlMSUEoNk6vDLoNctm08eEX8CbLo/Va7Ze0/WicsfVR3cLdILXgLnWc1TnfNEcfD1z3t5GlbW8EPiaaTt/Imd7bXNQ/1+f1xt1+Bquew28w9phu83no2XJaHGeSqVQKk3etVdd/rW/9yw6jTSTYs217RNnq6yBplM83Vx/4XKHX6Dx79O0c+xPyt178y4vuO3r6Ps4MJ4/n+f9yRecxlvj87q1cYfs9fVbvD1XlOGpp57k9W0nqyb7g9ATsBBCCBEDGoCFEEKIGNAALIQQQsTAeGtBG5DuyZ2tuZ6YrTrnumVSXKc24+qBZl1B0OkJFn0LE6wfra2xblIqTPD8rj6r16RbZadb7K6TvVPeIXt5+cNkp52u04HX2wb0ExYHJooi1Gr1wTM+AH9OGo3GA+bcH17z7HgN2IvIkX/PwGnALo/WWnwN1TdZO4N77yJEvL7dqtMSwfvbdvmZba/ROk3a12aOvObbdppxxNdI070GYS7ftdlif+sZ9+JHTERRhFpPrm6zzn5OTnG+9cwc99NtuLr0Nfcaw7TrLzw7xfey+o7TjLO8vWLJvf8S8XlOuTr2RVdLOpthe3OT83SvvP8+2fki38tvuX7D1SprwBu3b5K9W+a85ZnpEk/f4emVMq8vqegJWAghhIgBDcBCCCFEDGgAFkIIIWJgrBpwq93E+vrlu/bFG5zrtb3OusFk8wTZszNnyG5UWEdYWmSdYeXMSd6+04vKZdbLCjle3n872d5aI/vVC39BdqXC9V4nP/UbZJ9YOE92X11gpweqFPTwRFGE+hC6rdeA/bp8/XHzxZp9P9u++ueuNrLXUN38KZdfCaeposp6950brAE3nPaWT7M2mJniPq+W8nnATsP2ue1Okx7U79fnEfsawL4YdGeb7xl13x94cgaJIADtnpdI8k6z7XT47lKr8XFLu0TdlHv/JZ+bJtuMz3vHabr+PYhJp6FOTrJ/O652NVzcNVwNbl+kvFbn7b118W2yN7dYM148wXGXzbh+xCXWuEOH7+VXLl8iO51OxrsAg9ATsBBCCBEDGoCFEEKIGNAALIQQQsTAWDXgZqOGy++/ftd+5xb/jj/V5tyvt17/OdnVGutF1TLn4a6ssOb7oaeeJnt24UPsUIpzCnfKXDe33WZd5uoV9uenr/yA7OnJSbI3/t4zZC/MOH3K6WeR6+WayTq9TxyYgIBGuzV4xgct73T4hsuj9fW++2pBuxjqa6frNN+W66fblxvutLi0rxXtalVHLv+0vMXaXqfE+ZJ5vzxcbek+TdvZfn+9/wPygq3D22tuc37n6puvsr/TrGFPPvkxJIEQAvUqnnB5sOks5zvnCqzJ+rr1Ll0abTiN2NV+zk3wcU01OE43NrlmQa3uakG7Xude68+4WtbFSbe8i6PtMmu+kesf3HGabsrVwZ8q8f5V3fs2LffuwNwca8pJRU/AQgghRAxoABZCCCFiYOAAbGZnzexHZvammf3CzH6n+/m8mb1sZhe7/889enfFcUFxJ8aNYk6Mm/1owG0A/zaE8KqZTQH4azN7GcC/AvDDEMKXzewFAC8A+L2HrSiECI3GPc2p6HSPc0XWSC+/xnrPtVWu5dyss65Q3lkl++K775L99Ec/Qfb8Ka7VvL3GGnQ+zTrMtesXyd64xdvLR0tkv/Haj8je3WH/W67/cDrDp2P+BOdBHzNGEndRCGi2htGAWXxrOT05clpc2+VHdlwf14xrUt1yebOuNHNfXnGfpuo01OC2n3Y1fb2Y5/3NOC2t0eF8Ut+/2PeBDT4v2dHfT5n3J+vyhnfWr5F97W1+D2P29Fmyc2fOP3T7AxjhvS6g06PjFkucZ1uc5jG86eKg4jTT3RqfB2vycZ5a5HtpcZI15yeW+F6ytrbB699lTXV+ge/Faaf5zjqNNZXi6bfXuWZCsa+ogc+f56mNOr+bMDXjNHLXrziqPzxfP6kMfAIOIayGEF7t/l0G8CaAFQCfAfBid7YXAXz2UTkpjh+KOzFuFHNi3BxIAzaz8wB+GcArAJZCCKvAXuACOPmAZb5gZhfM7EK1cjQ6VIhkcdC46425zTsbfrIQAxn2Xlep1u43ixDEvgdgM5sE8F0AXwwh7Aya/wNCCF8LITwbQni2WCoNXkCIHg4Td70xN7dwNNIRRHIYxb2uVJwYvIA49uwrD9jMstgLyG+GEL7X/fiWmS2HEFbNbBnA7QevYY92u4U7a/dq05489RRNn0yxDlLd4aeXjDl9Ket7WvLudBpsb21x7ef8NOtR169zLep2hTXhOxus+U64PN0Jdgfvv/MLsre3OKdxe5f1t5lZ1oXOnD2H48wo4i6EgEbL6477x2uuTacBp1zudr8GzHmtKVfjt682sq+d7PsBu+/Mvr55e9flsvs8W+Plm06j9sOG96fq9ufGKl8jEwXWuH0+Zt35m8LD+x1nnSh+enaB7FrT1wbg/T8oo7rX7b3vcu9+Mz3Hmur8gtOA3X56yTTv+vG2mryfHfcuQtZppPlJrh3daPq4Zs00neblM67Pcsvle+dzPL9XfAsTHFlZd+/uuD7PtYo7jzO8/LTbnwC+tzdqh7/mx8l+3oI2AH8C4M0Qwld6Jr0E4Pnu388D+P7o3RPHFcWdGDeKOTFu9vME/E8A/EsAPzezn3U/+3cAvgzgO2b2eQDvA/jNR+OiOKYo7sS4UcyJsTJwAA4h/BX6GuXd5ddH644QeyjuxLhRzIlxM95+wK0Wbq5ev2s/s3yaplfK3LvUpcVissQfBLAukc6yTtAB1w/NOl2jkOZrrV5lHeHOLSf1uGS1oqv9nC+wf7UNXp/P7dva4vc7OhHrFsXi0ehpmWhCf43tAy3ep9Gy9tVuuzxdlxfbcTV9Oy2Xn+hqSfv+uK06z59zeb07W9zft3yb31PItlhby06x9ljpsP9Np70FV458/RZfo//7L/6c7Jkpzj/91U9+iuw5l9vedPmtLXM1hSO2F+dXyH7PXaO1Hb7GhEgyKkUphBBCxIAGYCGEECIGNAALIYQQMTBWDdgAZHo0pZ21KzS9tnmZ7NIU585lnH7WbrIel82wYOXkLZQK/MFUnvW9E3OsX9V22a43WNNNZ/j7i2VcT84c63+tpvO/xTmV7SZXCquW70AMRwgR2u3R5QG3naYbdTgGQstpwE0+x52014xdLek2Lx+5vOOW65O6vsaab6PMueZz7j2FdInzaEOFj01rlzXljssnDRWeHl27RPadOuvtm+49jxPznBccuYpRzQwfb2vw/lvwNYBdv+Iq778QSUZPwEIIIUQMaAAWQgghYkADsBBCCBEDY9WAUymj3Nb65g2avrbKetaUy1lMZ7geqq8VncqyHpSb4DzaUoH1trSx/lXI8/Scq2+6tcXrn57k5hK5PPuXmefDu+Pq9Oay/P0n7zTsRo01Z3EIDLBhvma6ora+NjJcDd6o4/KGXa3iKONykl2ebV9/X+P1VV3f2KarG5Eq8HsLVacx37x2neyOyxN+ssiaLVJ5MmfdNfPcEl8D1U1+j2GizHm69Vtcb73lrqnOBNf4LUQub9pcDWK447Gp7lfi6KAnYCGEECIGNAALIYQQMaABWAghhIiBsWrA6XQKMz19HTO7rBdFrkdlJ3jNljXZWt3pP7VtsotOT+u0nKYauX68TtM9s7xMdsrlFQenB0a+d2uG/a22XA5pyjUQdnpbaYpzNsXBCQHodEZXC7rjNNhalTXM7XWOwVDhet9zLtf85OklslPO17QTiQOHECZdrny9zP5Ud9ne3OT3EJq77O/sBL/HMDk9y7bTtM8vcv31SoGPz8UK145u3+D9tzusKTdnOE94fpavibaxZj3hNGFU+Z4iRJLRE7AQQggRAxqAhRBCiBjQACyEEELEwFg14ChEqNfuaTTVDa4rW3e9VSdTrH/lc1xrOV/kOrdVp2flA+tDweUU1pw+B9fr9dzZM2SvrLBdc/2DtzfXyL5zh+16g9dfmmT9LpdlDXr55BMQw+Nk3KFIuZhcW7tJ9us/e53suTx/x50/8QxPX+AYqLl645mM63nt3hOYy3PMbDuNt+Xek6jtsIa6ts21k2+/x7n55QJfo/N1nr7U5Gsum2eNOJ3jazrt3pvoNFijRo013Nw0n7yWq4/eqfL2+9YnRILRE7AQQggRAxqAhRBCiBjQACyEEELEwHg14E4Hu9vlu/YdVze2XOUkx4kK62GlIuccFqe4bmwE1pcyOd69XJbt8hbXjX3jjTfJXlw6SfbSMmvAi4s8/dSpE2RvbnKOJ4z1Q6/PFbKscU+YSzwWByeEofKAPVHE68q6mGq1nObqLrGO62e74WohW4q/E2dd3m/OePuFDF8T6VnWjIPb9UsRa9TltWtkV53Gve72p97ivN6PnOTt1VocszfKnOebK/EO1VwP7MIua77zxu9pVK5eJXt3izXgBnTNiKODnoCFEEKIGNAALIQQQsSABmAhhBAiBsaqARsM+fQ9jank8nh9c9RCkevSdlyv1VSa558ocp3ZiTzrUzmXM5lzOYrFEvvjczB3d8tkl4q8vukpXv7J8x9mf9Kcw/nOxUtkp9z+b2xwL1VxcKIQUK8fPjfU14L2GvDCAtfr/kf/8JfIXrvBeas//ev3yK7/v7fJnnAxVXAac859ZS4UOKZyebbTaV7g0jvcD/jq++zf3CK/t1Apc+68pfg9i40Vfu9htcaa8bUdPn4hxZpvdZPzkDNV7gkejLc/Xeb5N5usKWcm+D0KIZKMnoCFEEKIGNAALIQQQsSABmAhhBAiBsaqAYcoQqN2T49bnJ+j6WdXuP/u1DRrunA5jekc51QWSqwZT7jepjOu9vL0NNv/4B9/nOy809O2nV5Vr3Jd3cou1+HdWOM6utkcr296lnutVtz66g3OoRQHx8yQd+8CDLu+XooFjtGpIp9Ti1jz/cv/c4Hsy1dZ5280OMjbkc9hZjvvct295uvtyk3OfUeN84jX6rz+ZovfS9hM8/yNHM+/63p6r9b4Go22+T0Ka7M+n2rxNZTd4Xrq59019PY6X5Mhx/4KkWT0BCyEEELEgAZgIYQQIgYGDsBmVjCzn5jZ35rZL8zs33c//5CZvWJmF83sv5vZ6H7nE8cexZ0YN4o5MW72owE3APxaCGHXzLIA/srM/hzA7wL4jyGEb5vZVwF8HsB/fdiKAgztzr1Nnjp1lqZn86zfnDzJOYkLs5xz6fOA8wXOAZyc5Lzcctnl8U5yzuXp0yvsr8sB3Zxiva/mNNtmne2bq5zT2GqypltwOZ+VOuc0pvLHWs8aSdyZAZnM6I5jocAa6MlFzoNNu1rKq1evkN1scm3jkovZiQLf2yt1jplGm/NsO4E16foux1Dbzd9qs/8dc7Wsy7x8p8N5v7ddLev3KqwBd1w99qarDZ0KrPmWCpznW0jz+lIt3t5Ok58Z3irz+tspVzz7YIzsXifEfhj4BBz2+ODNiGz3XwDwawD+R/fzFwF89pF4KI4lijsxbhRzYtzsSwM2s7SZ/QzAbQAvA3gHwFYI4YOv19cArDxg2S+Y2QUzu9BoNO43ixD35bBx1xtzW+7NdSEexqjudT6jQYj7sa8BOITQCSH8EoAzAD4B4KP3m+0By34thPBsCOFZn9YjxMM4bNz1xtzs3Ox9FhHi/ozqXudbpwpxPw6UBxxC2DKzHwP4VQCzZpbpfjM8A+DG4K1lYQun7pprHdbLOq6ObKXC3yKreVfTt8nz541zCFdO8e7tuv7CNdfrNO1yDHddXi8iV9fW6WuTrg7t2dOnyX7/xk2y6y7nc32NczS3K1w397gyTNxFUUCtdvinkZTrzzvjcsfTTl/OOg346afOkf3RjzxB9jsXOSZaTsJsuzrWrZbTSFOskaYCa7BZ538o8jVhTkOOXB5v1HIxH7FGXefNoe00YLhrquV+BQttthtNd40bL191ecq3I77mrD2aX9mGvtcJsQ/28xb0opnNdv+eAPDPALwJ4EcAfqM72/MAvv+onBTHD8WdGDeKOTFu9vMEvAzgRTNLY2/A/k4I4X+Z2RsAvm1mfwjgbwD8ySP0Uxw/FHdi3CjmxFgZOACHEF4D8Mv3+fxd7GkkQowcxZ0YN4o5MW7M57o+0o2ZrQG4AuAEgPWxbfjgyL/heJB/50IIi+N0RDE3Mo6qf2OPOUBxN0KOqn/7iruxDsB3N2p2IYTw7Ng3vE/k33Ak0b8k+tSL/BuOpPqXVL8+QP4Nx7D+qRa0EEIIEQMagIUQQogYiGsA/lpM290v8m84kuhfEn3qRf4NR1L9S6pfHyD/hmMo/2LRgIUQQojjjn6CFkIIIWJAA7AQQggRA2MdgM3sn5vZW2Z2ycxeGOe2H4SZfd3MbpvZ6z2fzZvZy90G3C+b2VxMvp01sx+Z2ZvdBuG/kzD/jkQD86TFXZJjruuL4m54HxMVc0Cy4+7YxlwIYSz/AKSx19rrSQA5AH8L4GPj2v5D/PqnAD4O4PWez/4YwAvdv18A8Ecx+bYM4OPdv6cAvA3gYwnyzwBMdv/OAngFe8XrvwPgc93Pvwrgt2M8v4mLuyTHnOLu8Yy5pMfdcY25ce7AJwH8oMf+EoAvxXEw7+PbeReUbwFY7gmMt+L2sevL9wE8l0T/ABQBvArgV7BXGSZzv/Meg1+JjLujEnNdfxR3B/MpkTHX9eVIxN1xiblx/gS9AuBqj/3AxtYJYCmEsAoA3f9PxuwPzOw89urUvoIE+WdDNDAfE0cl7hJzTntR3B2KoxJzQILO6Qccp5gb5wBs9/lMOVD7wMwmAXwXwBdDCDtx+9NLGKKB+ZhQ3B0Sxd2hUcwdkuMWc+McgK8BONtjJ7mx9S0zWwaA7v+343LEzLLYC8hvhhC+lzT/PiCEsAXgx+hpYN6dFPd5Pipxl6hzqrgbiqMSc0CCzulxjLlxDsA/BfB0962xHIDPAXhpjNs/CC9hr/E2EGMDbjMz7PUefTOE8JWeSUnx7yg0MD8qcZeIcwoo7kbAUYk5IDnn9HjG3JjF609j7+22dwD8ftxietenbwFYBdDC3jfXzwNYAPBDABe7/8/H5NunsPeTxmsAftb99+kE+fcM9hqUvwbgdQB/0P38SQA/AXAJwJ8CyMd8jhMVd0mOOcXd4xlzSY+74xpzKkUphBBCxIAqYQkhhBAxoAFYCCGEiAENwEIIIUQMaAAWQgghYkADsBBCCBEDGoCFEEKIGNAALIQQQsTA/weysYIOa3/wJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 3\n",
    "rows = 3\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.5, height_shift_range=0.5)\n",
    "datagen.fit(train_x)\n",
    "# configure batch size and retrieve one batch of images\n",
    "X_batch, y_batch = datagen.flow(train_x, train_y, batch_size=9)[0]\n",
    "for i in range(1, columns*rows+1):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_batch[i-1], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Sequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x, y, batch_size):\n",
    "        self.x, self.y = x, y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    '''\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = da.random.choice(len(self.x), len(self.x), False, chunks=len(self.x))\n",
    "    '''\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return dask.compute(batch_x, batch_y)\n",
    "\n",
    "def build_block(input_layer, filters, norm=True, k=[3,3]):\n",
    "    layer = tf.keras.layers.Conv2D(filters, kernel_size=(k[0], k[1]), padding='same', use_bias=False, kernel_initializer='glorot_uniform')(input_layer)\n",
    "    if norm:\n",
    "        layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "    layer = tf.keras.layers.Activation('elu')(layer)\n",
    "    return layer\n",
    "\n",
    "def build_model(num_class):\n",
    "    image_input = tf.keras.Input(shape=(32, 32, 3), name='input_layer')\n",
    "    conv_1 = build_block(image_input, 48)\n",
    "    conv_2 = build_block(conv_1, 48)\n",
    "    pool_1 = tf.keras.layers.MaxPooling2D(padding='same')(conv_2)\n",
    "    drop_1 = tf.keras.layers.Dropout(0.6)(pool_1)\n",
    "    conv_3 = build_block(drop_1, 96)\n",
    "    conv_4 = build_block(conv_3, 96)\n",
    "    pool_2 = tf.keras.layers.MaxPooling2D(padding='same')(conv_4)\n",
    "    drop_2 = tf.keras.layers.Dropout(0.6)(pool_2)\n",
    "    conv_5 = build_block(drop_2, 192)\n",
    "    conv_6 = build_block(conv_5, 192)\n",
    "    pool_3 = tf.keras.layers.MaxPooling2D(padding='same')(conv_6)\n",
    "    drop_3 = tf.keras.layers.Dropout(0.6)(pool_3)\n",
    "    conv_7 = build_block(drop_3, 192, False, [1,1])\n",
    "    gap = tf.keras.layers.GlobalAvgPool2D()(conv_7)\n",
    "    logits = tf.keras.layers.Dense(units=num_class, activation='softmax', bias_initializer='ones', kernel_initializer='glorot_uniform')(gap)\n",
    "    model = tf.keras.Model(inputs=image_input, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 48)        1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 48)        20736     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 96)        41472     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 96)        82944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 192)         165888    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 192)         331776    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 192)         36864     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1930      \n",
      "=================================================================\n",
      "Total params: 685,594\n",
      "Trainable params: 684,250\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\niterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\\nfeatures, labels = iterator.get_next()\\n\\ntraining_init_op = iterator.make_initializer(train_dataset)\\ntesting_init_op = iterator.make_initializer(test_dataset)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate, batch_size, num_class = 0.001, 128, 10\n",
    "\n",
    "dy_train = tf.data.Dataset.from_tensor_slices(train_y)\n",
    "dx_train = tf.data.Dataset.from_tensor_slices(train_x[0:10000])\n",
    "\n",
    "for i in range(1, 5):\n",
    "    tmp = tf.data.Dataset.from_tensor_slices(train_x[i*10000:(i+1)*10000])\n",
    "    dx_train.concatenate(tmp)\n",
    "    \n",
    "train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(100).batch(batch_size).repeat().prefetch(1)\n",
    "\n",
    "dx_test = tf.data.Dataset.from_tensor_slices(test_x)\n",
    "dy_test = tf.data.Dataset.from_tensor_slices(test_y)\n",
    "test_dataset = tf.data.Dataset.zip((dx_test, dy_test)).repeat().batch(batch_size).prefetch(1)\n",
    "'''\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "features, labels = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "testing_init_op = iterator.make_initializer(test_dataset)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 16s 2ms/step\n",
      "[0.4587925143584609, 0.9062]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights_d2.best.hdf5\")\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9782\n",
      "Epoch 00001: val_acc improved from -inf to 0.89463, saving model to weights_d3.best.hdf5\n",
      "390/390 [==============================] - 38s 97ms/step - loss: 0.0618 - acc: 0.9782 - val_loss: 0.5091 - val_acc: 0.8946\n",
      "Epoch 2/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9786\n",
      "Epoch 00002: val_acc improved from 0.89463 to 0.90004, saving model to weights_d3.best.hdf5\n",
      "390/390 [==============================] - 33s 86ms/step - loss: 0.0619 - acc: 0.9786 - val_loss: 0.5019 - val_acc: 0.9000\n",
      "Epoch 3/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9772\n",
      "Epoch 00003: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 33s 85ms/step - loss: 0.0648 - acc: 0.9772 - val_loss: 0.4970 - val_acc: 0.8989\n",
      "Epoch 4/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9777\n",
      "Epoch 00004: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 34s 86ms/step - loss: 0.0621 - acc: 0.9778 - val_loss: 0.5210 - val_acc: 0.8947\n",
      "Epoch 5/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9786\n",
      "Epoch 00005: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0608 - acc: 0.9785 - val_loss: 0.5053 - val_acc: 0.8990\n",
      "Epoch 6/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9784\n",
      "Epoch 00006: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0617 - acc: 0.9784 - val_loss: 0.4987 - val_acc: 0.8973\n",
      "Epoch 7/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9777\n",
      "Epoch 00007: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0620 - acc: 0.9777 - val_loss: 0.5229 - val_acc: 0.8977\n",
      "Epoch 8/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9781\n",
      "Epoch 00008: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0613 - acc: 0.9781 - val_loss: 0.5090 - val_acc: 0.8967\n",
      "Epoch 9/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9776\n",
      "Epoch 00009: val_acc did not improve from 0.90004\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0628 - acc: 0.9776 - val_loss: 0.4806 - val_acc: 0.8999\n",
      "Epoch 10/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9777\n",
      "Epoch 00010: val_acc improved from 0.90004 to 0.90284, saving model to weights_d3.best.hdf5\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0652 - acc: 0.9777 - val_loss: 0.4626 - val_acc: 0.9028\n",
      "Epoch 11/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9772\n",
      "Epoch 00011: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0651 - acc: 0.9773 - val_loss: 0.4881 - val_acc: 0.8980\n",
      "Epoch 12/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9774\n",
      "Epoch 00012: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0646 - acc: 0.9775 - val_loss: 0.4861 - val_acc: 0.8958\n",
      "Epoch 13/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9787\n",
      "Epoch 00013: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0614 - acc: 0.9787 - val_loss: 0.4798 - val_acc: 0.9013\n",
      "Epoch 14/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9792\n",
      "Epoch 00014: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0622 - acc: 0.9792 - val_loss: 0.5104 - val_acc: 0.9001\n",
      "Epoch 15/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9772\n",
      "Epoch 00015: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 34s 88ms/step - loss: 0.0629 - acc: 0.9772 - val_loss: 0.4811 - val_acc: 0.9016\n",
      "Epoch 16/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9764\n",
      "Epoch 00016: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0674 - acc: 0.9763 - val_loss: 0.4647 - val_acc: 0.9003\n",
      "Epoch 17/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9776\n",
      "Epoch 00017: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0647 - acc: 0.9776 - val_loss: 0.4778 - val_acc: 0.9010\n",
      "Epoch 18/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9788\n",
      "Epoch 00018: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0606 - acc: 0.9788 - val_loss: 0.4793 - val_acc: 0.8973\n",
      "Epoch 19/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9773\n",
      "Epoch 00019: val_acc did not improve from 0.90284\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0650 - acc: 0.9773 - val_loss: 0.4988 - val_acc: 0.8950\n",
      "Epoch 20/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9775\n",
      "Epoch 00020: val_acc improved from 0.90284 to 0.90315, saving model to weights_d3.best.hdf5\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0629 - acc: 0.9775 - val_loss: 0.4612 - val_acc: 0.9031\n",
      "Epoch 21/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9790\n",
      "Epoch 00021: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0608 - acc: 0.9791 - val_loss: 0.5110 - val_acc: 0.8985\n",
      "Epoch 22/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9763\n",
      "Epoch 00022: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0662 - acc: 0.9762 - val_loss: 0.4730 - val_acc: 0.9030\n",
      "Epoch 23/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9771\n",
      "Epoch 00023: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0632 - acc: 0.9771 - val_loss: 0.4559 - val_acc: 0.9030\n",
      "Epoch 24/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9782\n",
      "Epoch 00024: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0616 - acc: 0.9781 - val_loss: 0.4672 - val_acc: 0.9008\n",
      "Epoch 25/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9787\n",
      "Epoch 00025: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0620 - acc: 0.9786 - val_loss: 0.4956 - val_acc: 0.9000\n",
      "Epoch 26/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9791\n",
      "Epoch 00026: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0594 - acc: 0.9792 - val_loss: 0.4768 - val_acc: 0.8975\n",
      "Epoch 27/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9784\n",
      "Epoch 00027: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0619 - acc: 0.9784 - val_loss: 0.4655 - val_acc: 0.9009\n",
      "Epoch 28/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9779\n",
      "Epoch 00028: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0616 - acc: 0.9779 - val_loss: 0.5005 - val_acc: 0.8983\n",
      "Epoch 29/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9786\n",
      "Epoch 00029: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0606 - acc: 0.9786 - val_loss: 0.4708 - val_acc: 0.9015\n",
      "Epoch 30/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9774\n",
      "Epoch 00030: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0641 - acc: 0.9774 - val_loss: 0.4869 - val_acc: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9790\n",
      "Epoch 00031: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0595 - acc: 0.9790 - val_loss: 0.5212 - val_acc: 0.8938\n",
      "Epoch 32/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9772\n",
      "Epoch 00032: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0633 - acc: 0.9772 - val_loss: 0.4783 - val_acc: 0.9016\n",
      "Epoch 33/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9786\n",
      "Epoch 00033: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0610 - acc: 0.9785 - val_loss: 0.5115 - val_acc: 0.8939\n",
      "Epoch 34/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9778\n",
      "Epoch 00034: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0637 - acc: 0.9778 - val_loss: 0.5232 - val_acc: 0.8970\n",
      "Epoch 35/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9784\n",
      "Epoch 00035: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.0619 - acc: 0.9784 - val_loss: 0.5093 - val_acc: 0.8976\n",
      "Epoch 36/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9794\n",
      "Epoch 00036: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0597 - acc: 0.9794 - val_loss: 0.4762 - val_acc: 0.9023\n",
      "Epoch 37/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9767\n",
      "Epoch 00037: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0655 - acc: 0.9767 - val_loss: 0.4880 - val_acc: 0.9000\n",
      "Epoch 38/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9779\n",
      "Epoch 00038: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0618 - acc: 0.9779 - val_loss: 0.5124 - val_acc: 0.8963\n",
      "Epoch 39/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9779\n",
      "Epoch 00039: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0610 - acc: 0.9779 - val_loss: 0.4926 - val_acc: 0.8997\n",
      "Epoch 40/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9786\n",
      "Epoch 00040: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0602 - acc: 0.9785 - val_loss: 0.4900 - val_acc: 0.9001\n",
      "Epoch 41/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9779\n",
      "Epoch 00041: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0623 - acc: 0.9779 - val_loss: 0.4593 - val_acc: 0.9020\n",
      "Epoch 42/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9773\n",
      "Epoch 00042: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0630 - acc: 0.9773 - val_loss: 0.4736 - val_acc: 0.9023\n",
      "Epoch 43/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9776\n",
      "Epoch 00043: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0637 - acc: 0.9776 - val_loss: 0.4723 - val_acc: 0.9021\n",
      "Epoch 44/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9776\n",
      "Epoch 00044: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0635 - acc: 0.9777 - val_loss: 0.4817 - val_acc: 0.9006\n",
      "Epoch 45/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9783\n",
      "Epoch 00045: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9783 - val_loss: 0.4900 - val_acc: 0.8996\n",
      "Epoch 46/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9785\n",
      "Epoch 00046: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0612 - acc: 0.9785 - val_loss: 0.5074 - val_acc: 0.8966\n",
      "Epoch 47/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9778\n",
      "Epoch 00047: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0617 - acc: 0.9779 - val_loss: 0.5215 - val_acc: 0.8953\n",
      "Epoch 48/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9771\n",
      "Epoch 00048: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0674 - acc: 0.9771 - val_loss: 0.4683 - val_acc: 0.8992\n",
      "Epoch 49/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9789\n",
      "Epoch 00049: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0602 - acc: 0.9789 - val_loss: 0.4954 - val_acc: 0.8994\n",
      "Epoch 50/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9771\n",
      "Epoch 00050: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0630 - acc: 0.9772 - val_loss: 0.4847 - val_acc: 0.8991\n",
      "Epoch 51/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9792\n",
      "Epoch 00051: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0609 - acc: 0.9791 - val_loss: 0.4749 - val_acc: 0.9028\n",
      "Epoch 52/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9784\n",
      "Epoch 00052: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0595 - acc: 0.9783 - val_loss: 0.5179 - val_acc: 0.8963\n",
      "Epoch 53/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9773\n",
      "Epoch 00053: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0635 - acc: 0.9773 - val_loss: 0.5174 - val_acc: 0.8960\n",
      "Epoch 54/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9772\n",
      "Epoch 00054: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 35s 89ms/step - loss: 0.0634 - acc: 0.9773 - val_loss: 0.4847 - val_acc: 0.9013\n",
      "Epoch 55/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9777\n",
      "Epoch 00055: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0632 - acc: 0.9777 - val_loss: 0.4811 - val_acc: 0.9025\n",
      "Epoch 56/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9777\n",
      "Epoch 00056: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.0632 - acc: 0.9776 - val_loss: 0.5037 - val_acc: 0.8965\n",
      "Epoch 57/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9781\n",
      "Epoch 00057: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.4996 - val_acc: 0.8983\n",
      "Epoch 58/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9792\n",
      "Epoch 00058: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0589 - acc: 0.9791 - val_loss: 0.4834 - val_acc: 0.9028\n",
      "Epoch 59/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9771\n",
      "Epoch 00059: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0662 - acc: 0.9772 - val_loss: 0.4880 - val_acc: 0.8994\n",
      "Epoch 60/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9777\n",
      "Epoch 00060: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0625 - acc: 0.9777 - val_loss: 0.4780 - val_acc: 0.9011\n",
      "Epoch 61/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9776\n",
      "Epoch 00061: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0638 - acc: 0.9776 - val_loss: 0.4809 - val_acc: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9778\n",
      "Epoch 00062: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0626 - acc: 0.9778 - val_loss: 0.5197 - val_acc: 0.8917\n",
      "Epoch 63/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9781\n",
      "Epoch 00063: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0604 - acc: 0.9781 - val_loss: 0.4954 - val_acc: 0.8998\n",
      "Epoch 64/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9781\n",
      "Epoch 00064: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0610 - acc: 0.9780 - val_loss: 0.4840 - val_acc: 0.9010\n",
      "Epoch 65/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9785\n",
      "Epoch 00065: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0593 - acc: 0.9785 - val_loss: 0.4701 - val_acc: 0.9005\n",
      "Epoch 66/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9766\n",
      "Epoch 00066: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0656 - acc: 0.9766 - val_loss: 0.5071 - val_acc: 0.8968\n",
      "Epoch 67/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9787\n",
      "Epoch 00067: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0599 - acc: 0.9787 - val_loss: 0.5495 - val_acc: 0.8915\n",
      "Epoch 68/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9785\n",
      "Epoch 00068: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0638 - acc: 0.9785 - val_loss: 0.4991 - val_acc: 0.8982\n",
      "Epoch 69/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9774\n",
      "Epoch 00069: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0633 - acc: 0.9773 - val_loss: 0.4859 - val_acc: 0.9023\n",
      "Epoch 70/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9785\n",
      "Epoch 00070: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0625 - acc: 0.9785 - val_loss: 0.5160 - val_acc: 0.8979\n",
      "Epoch 71/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9778\n",
      "Epoch 00071: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0627 - acc: 0.9779 - val_loss: 0.5011 - val_acc: 0.8958\n",
      "Epoch 72/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9780\n",
      "Epoch 00072: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0625 - acc: 0.9780 - val_loss: 0.5235 - val_acc: 0.8941\n",
      "Epoch 73/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9778\n",
      "Epoch 00073: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0624 - acc: 0.9778 - val_loss: 0.4922 - val_acc: 0.8990\n",
      "Epoch 74/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9796\n",
      "Epoch 00074: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0565 - acc: 0.9796 - val_loss: 0.4713 - val_acc: 0.9005\n",
      "Epoch 75/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9783\n",
      "Epoch 00075: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0619 - acc: 0.9783 - val_loss: 0.4851 - val_acc: 0.8988\n",
      "Epoch 76/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9779\n",
      "Epoch 00076: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0616 - acc: 0.9778 - val_loss: 0.5252 - val_acc: 0.8940\n",
      "Epoch 77/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9788\n",
      "Epoch 00077: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0599 - acc: 0.9787 - val_loss: 0.4980 - val_acc: 0.9017\n",
      "Epoch 78/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9773\n",
      "Epoch 00078: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0636 - acc: 0.9774 - val_loss: 0.4936 - val_acc: 0.9002\n",
      "Epoch 79/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9784\n",
      "Epoch 00079: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0636 - acc: 0.9783 - val_loss: 0.4705 - val_acc: 0.9001\n",
      "Epoch 80/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9773\n",
      "Epoch 00080: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0621 - acc: 0.9773 - val_loss: 0.4711 - val_acc: 0.9023\n",
      "Epoch 81/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9792\n",
      "Epoch 00081: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0614 - acc: 0.9792 - val_loss: 0.5232 - val_acc: 0.8962\n",
      "Epoch 82/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9777\n",
      "Epoch 00082: val_acc did not improve from 0.90315\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0620 - acc: 0.9777 - val_loss: 0.4695 - val_acc: 0.9009\n",
      "Epoch 83/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9771\n",
      "Epoch 00083: val_acc improved from 0.90315 to 0.90585, saving model to weights_d3.best.hdf5\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.0642 - acc: 0.9771 - val_loss: 0.4623 - val_acc: 0.9058\n",
      "Epoch 84/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9790\n",
      "Epoch 00084: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0589 - acc: 0.9790 - val_loss: 0.4956 - val_acc: 0.8989\n",
      "Epoch 85/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9787\n",
      "Epoch 00085: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0590 - acc: 0.9787 - val_loss: 0.5031 - val_acc: 0.8991\n",
      "Epoch 86/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9784\n",
      "Epoch 00086: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0626 - acc: 0.9784 - val_loss: 0.4774 - val_acc: 0.8997\n",
      "Epoch 87/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9775\n",
      "Epoch 00087: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0636 - acc: 0.9776 - val_loss: 0.5108 - val_acc: 0.8963\n",
      "Epoch 88/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9776\n",
      "Epoch 00088: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0643 - acc: 0.9776 - val_loss: 0.4722 - val_acc: 0.9002\n",
      "Epoch 89/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9781\n",
      "Epoch 00089: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0631 - acc: 0.9780 - val_loss: 0.4806 - val_acc: 0.9019\n",
      "Epoch 90/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9785\n",
      "Epoch 00090: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0621 - acc: 0.9785 - val_loss: 0.4755 - val_acc: 0.9031\n",
      "Epoch 91/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9790\n",
      "Epoch 00091: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0587 - acc: 0.9791 - val_loss: 0.5212 - val_acc: 0.8979\n",
      "Epoch 92/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9777\n",
      "Epoch 00092: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0625 - acc: 0.9777 - val_loss: 0.4789 - val_acc: 0.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9786\n",
      "Epoch 00093: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0618 - acc: 0.9787 - val_loss: 0.4962 - val_acc: 0.8960\n",
      "Epoch 94/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9788\n",
      "Epoch 00094: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0611 - acc: 0.9788 - val_loss: 0.4741 - val_acc: 0.9027\n",
      "Epoch 95/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9783\n",
      "Epoch 00095: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0603 - acc: 0.9783 - val_loss: 0.5041 - val_acc: 0.8978\n",
      "Epoch 96/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9781\n",
      "Epoch 00096: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0633 - acc: 0.9780 - val_loss: 0.4961 - val_acc: 0.8978\n",
      "Epoch 97/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9776\n",
      "Epoch 00097: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0633 - acc: 0.9776 - val_loss: 0.4921 - val_acc: 0.9014\n",
      "Epoch 98/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9783\n",
      "Epoch 00098: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0607 - acc: 0.9784 - val_loss: 0.5068 - val_acc: 0.8996\n",
      "Epoch 99/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9788\n",
      "Epoch 00099: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0589 - acc: 0.9787 - val_loss: 0.5269 - val_acc: 0.8957\n",
      "Epoch 100/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9788\n",
      "Epoch 00100: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0609 - acc: 0.9788 - val_loss: 0.4723 - val_acc: 0.9019\n",
      "Epoch 101/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9790\n",
      "Epoch 00101: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0606 - acc: 0.9790 - val_loss: 0.4890 - val_acc: 0.9010\n",
      "Epoch 102/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9786\n",
      "Epoch 00102: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0611 - acc: 0.9786 - val_loss: 0.4991 - val_acc: 0.9009\n",
      "Epoch 103/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9784\n",
      "Epoch 00103: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0607 - acc: 0.9784 - val_loss: 0.4839 - val_acc: 0.9021\n",
      "Epoch 104/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9780\n",
      "Epoch 00104: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0642 - acc: 0.9779 - val_loss: 0.4849 - val_acc: 0.9014\n",
      "Epoch 105/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9788\n",
      "Epoch 00105: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0613 - acc: 0.9788 - val_loss: 0.4876 - val_acc: 0.9028\n",
      "Epoch 106/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9775\n",
      "Epoch 00106: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0653 - acc: 0.9775 - val_loss: 0.5279 - val_acc: 0.8962\n",
      "Epoch 107/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9786\n",
      "Epoch 00107: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0632 - acc: 0.9787 - val_loss: 0.4768 - val_acc: 0.8992\n",
      "Epoch 108/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9784\n",
      "Epoch 00108: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0608 - acc: 0.9784 - val_loss: 0.4942 - val_acc: 0.8980\n",
      "Epoch 109/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9783\n",
      "Epoch 00109: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0608 - acc: 0.9783 - val_loss: 0.5154 - val_acc: 0.8975\n",
      "Epoch 110/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9785\n",
      "Epoch 00110: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0612 - acc: 0.9784 - val_loss: 0.4761 - val_acc: 0.9024\n",
      "Epoch 111/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9789\n",
      "Epoch 00111: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0595 - acc: 0.9789 - val_loss: 0.5157 - val_acc: 0.8983\n",
      "Epoch 112/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9778\n",
      "Epoch 00112: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0633 - acc: 0.9778 - val_loss: 0.5468 - val_acc: 0.8900\n",
      "Epoch 113/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9777\n",
      "Epoch 00113: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0624 - acc: 0.9777 - val_loss: 0.5353 - val_acc: 0.8926\n",
      "Epoch 114/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9785\n",
      "Epoch 00114: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0601 - acc: 0.9785 - val_loss: 0.4962 - val_acc: 0.8966\n",
      "Epoch 115/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9788\n",
      "Epoch 00115: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0610 - acc: 0.9788 - val_loss: 0.4990 - val_acc: 0.8983\n",
      "Epoch 116/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9797\n",
      "Epoch 00116: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0583 - acc: 0.9796 - val_loss: 0.4541 - val_acc: 0.9028\n",
      "Epoch 117/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9796\n",
      "Epoch 00117: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0582 - acc: 0.9797 - val_loss: 0.4828 - val_acc: 0.9013\n",
      "Epoch 118/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9782\n",
      "Epoch 00118: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0611 - acc: 0.9782 - val_loss: 0.4854 - val_acc: 0.9003\n",
      "Epoch 119/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9799\n",
      "Epoch 00119: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0585 - acc: 0.9798 - val_loss: 0.5091 - val_acc: 0.8989\n",
      "Epoch 120/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9787\n",
      "Epoch 00120: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0623 - acc: 0.9786 - val_loss: 0.4909 - val_acc: 0.9021\n",
      "Epoch 121/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9785\n",
      "Epoch 00121: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0613 - acc: 0.9784 - val_loss: 0.4811 - val_acc: 0.8989\n",
      "Epoch 122/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9785\n",
      "Epoch 00122: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0601 - acc: 0.9785 - val_loss: 0.5150 - val_acc: 0.8968\n",
      "Epoch 123/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9785\n",
      "Epoch 00123: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0614 - acc: 0.9785 - val_loss: 0.4692 - val_acc: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9787\n",
      "Epoch 00124: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0616 - acc: 0.9787 - val_loss: 0.4785 - val_acc: 0.9013\n",
      "Epoch 125/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9779\n",
      "Epoch 00125: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0627 - acc: 0.9779 - val_loss: 0.5236 - val_acc: 0.8947\n",
      "Epoch 126/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9776\n",
      "Epoch 00126: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0638 - acc: 0.9776 - val_loss: 0.4871 - val_acc: 0.8988\n",
      "Epoch 127/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9788\n",
      "Epoch 00127: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0594 - acc: 0.9788 - val_loss: 0.4788 - val_acc: 0.9014\n",
      "Epoch 128/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9779\n",
      "Epoch 00128: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0621 - acc: 0.9779 - val_loss: 0.4679 - val_acc: 0.9039\n",
      "Epoch 129/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9792\n",
      "Epoch 00129: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0604 - acc: 0.9792 - val_loss: 0.4842 - val_acc: 0.9013\n",
      "Epoch 130/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9788\n",
      "Epoch 00130: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0604 - acc: 0.9787 - val_loss: 0.5256 - val_acc: 0.8935\n",
      "Epoch 131/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9791\n",
      "Epoch 00131: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0603 - acc: 0.9791 - val_loss: 0.5046 - val_acc: 0.8977\n",
      "Epoch 132/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9786\n",
      "Epoch 00132: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0595 - acc: 0.9786 - val_loss: 0.4993 - val_acc: 0.8965\n",
      "Epoch 133/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9787\n",
      "Epoch 00133: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0612 - acc: 0.9787 - val_loss: 0.4866 - val_acc: 0.8991\n",
      "Epoch 134/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9789\n",
      "Epoch 00134: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0595 - acc: 0.9788 - val_loss: 0.4787 - val_acc: 0.9029\n",
      "Epoch 135/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9783\n",
      "Epoch 00135: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0627 - acc: 0.9783 - val_loss: 0.5007 - val_acc: 0.8990\n",
      "Epoch 136/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9780\n",
      "Epoch 00136: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.4768 - val_acc: 0.9021\n",
      "Epoch 137/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9785\n",
      "Epoch 00137: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0625 - acc: 0.9785 - val_loss: 0.4878 - val_acc: 0.9013\n",
      "Epoch 138/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9774\n",
      "Epoch 00138: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0635 - acc: 0.9774 - val_loss: 0.5051 - val_acc: 0.8980\n",
      "Epoch 139/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9770\n",
      "Epoch 00139: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0662 - acc: 0.9770 - val_loss: 0.4638 - val_acc: 0.9024\n",
      "Epoch 140/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9777\n",
      "Epoch 00140: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0624 - acc: 0.9777 - val_loss: 0.5043 - val_acc: 0.8953\n",
      "Epoch 141/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9785\n",
      "Epoch 00141: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0596 - acc: 0.9785 - val_loss: 0.5179 - val_acc: 0.8968\n",
      "Epoch 142/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9788\n",
      "Epoch 00142: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0603 - acc: 0.9788 - val_loss: 0.4959 - val_acc: 0.9003\n",
      "Epoch 143/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9773\n",
      "Epoch 00143: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0637 - acc: 0.9772 - val_loss: 0.5090 - val_acc: 0.8972\n",
      "Epoch 144/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9785\n",
      "Epoch 00144: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9785 - val_loss: 0.4889 - val_acc: 0.8985\n",
      "Epoch 145/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9784\n",
      "Epoch 00145: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9784 - val_loss: 0.5059 - val_acc: 0.8972\n",
      "Epoch 146/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9785\n",
      "Epoch 00146: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0614 - acc: 0.9784 - val_loss: 0.5059 - val_acc: 0.8967\n",
      "Epoch 147/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9784\n",
      "Epoch 00147: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0606 - acc: 0.9784 - val_loss: 0.4905 - val_acc: 0.8993\n",
      "Epoch 148/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9788\n",
      "Epoch 00148: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0603 - acc: 0.9789 - val_loss: 0.4837 - val_acc: 0.9013\n",
      "Epoch 149/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9780\n",
      "Epoch 00149: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0640 - acc: 0.9780 - val_loss: 0.5104 - val_acc: 0.8956\n",
      "Epoch 150/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9792\n",
      "Epoch 00150: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0592 - acc: 0.9792 - val_loss: 0.4855 - val_acc: 0.9015\n",
      "Epoch 151/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9780\n",
      "Epoch 00151: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0615 - acc: 0.9779 - val_loss: 0.5345 - val_acc: 0.8951\n",
      "Epoch 152/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9762\n",
      "Epoch 00152: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0642 - acc: 0.9763 - val_loss: 0.5155 - val_acc: 0.8944\n",
      "Epoch 153/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9785\n",
      "Epoch 00153: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0607 - acc: 0.9785 - val_loss: 0.4648 - val_acc: 0.9034\n",
      "Epoch 154/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9772\n",
      "Epoch 00154: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0642 - acc: 0.9772 - val_loss: 0.4878 - val_acc: 0.8987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9783\n",
      "Epoch 00155: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0590 - acc: 0.9783 - val_loss: 0.5131 - val_acc: 0.8966\n",
      "Epoch 156/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9793\n",
      "Epoch 00156: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0583 - acc: 0.9793 - val_loss: 0.5016 - val_acc: 0.8985\n",
      "Epoch 157/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9784\n",
      "Epoch 00157: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0615 - acc: 0.9784 - val_loss: 0.4912 - val_acc: 0.8955\n",
      "Epoch 158/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9781\n",
      "Epoch 00158: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0602 - acc: 0.9781 - val_loss: 0.5415 - val_acc: 0.8938\n",
      "Epoch 159/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9779\n",
      "Epoch 00159: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0626 - acc: 0.9779 - val_loss: 0.5269 - val_acc: 0.8959\n",
      "Epoch 160/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9796\n",
      "Epoch 00160: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0597 - acc: 0.9796 - val_loss: 0.4801 - val_acc: 0.9007\n",
      "Epoch 161/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9793\n",
      "Epoch 00161: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0599 - acc: 0.9793 - val_loss: 0.4979 - val_acc: 0.8984\n",
      "Epoch 162/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9782\n",
      "Epoch 00162: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0597 - acc: 0.9782 - val_loss: 0.5020 - val_acc: 0.9010\n",
      "Epoch 163/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9778\n",
      "Epoch 00163: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0628 - acc: 0.9778 - val_loss: 0.4801 - val_acc: 0.9022\n",
      "Epoch 164/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9794\n",
      "Epoch 00164: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0574 - acc: 0.9794 - val_loss: 0.4850 - val_acc: 0.9011\n",
      "Epoch 165/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9776\n",
      "Epoch 00165: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0610 - acc: 0.9775 - val_loss: 0.4712 - val_acc: 0.9036\n",
      "Epoch 166/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9786\n",
      "Epoch 00166: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0617 - acc: 0.9786 - val_loss: 0.5269 - val_acc: 0.8969\n",
      "Epoch 167/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9777\n",
      "Epoch 00167: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0631 - acc: 0.9777 - val_loss: 0.5152 - val_acc: 0.8932\n",
      "Epoch 168/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9797\n",
      "Epoch 00168: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0601 - acc: 0.9797 - val_loss: 0.5199 - val_acc: 0.8943\n",
      "Epoch 169/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9787\n",
      "Epoch 00169: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0615 - acc: 0.9788 - val_loss: 0.4910 - val_acc: 0.8981\n",
      "Epoch 170/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9777\n",
      "Epoch 00170: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0626 - acc: 0.9777 - val_loss: 0.4720 - val_acc: 0.9009\n",
      "Epoch 171/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9779\n",
      "Epoch 00171: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0622 - acc: 0.9779 - val_loss: 0.4641 - val_acc: 0.9023\n",
      "Epoch 172/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9783\n",
      "Epoch 00172: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0630 - acc: 0.9783 - val_loss: 0.5027 - val_acc: 0.8951\n",
      "Epoch 173/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9787\n",
      "Epoch 00173: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0614 - acc: 0.9787 - val_loss: 0.4919 - val_acc: 0.8948\n",
      "Epoch 174/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9772\n",
      "Epoch 00174: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0637 - acc: 0.9773 - val_loss: 0.5155 - val_acc: 0.8947\n",
      "Epoch 175/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9788\n",
      "Epoch 00175: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9789 - val_loss: 0.5049 - val_acc: 0.8999\n",
      "Epoch 176/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9779\n",
      "Epoch 00176: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0634 - acc: 0.9778 - val_loss: 0.4909 - val_acc: 0.8998\n",
      "Epoch 177/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9781\n",
      "Epoch 00177: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0621 - acc: 0.9780 - val_loss: 0.5054 - val_acc: 0.8999\n",
      "Epoch 178/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9778\n",
      "Epoch 00178: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0634 - acc: 0.9779 - val_loss: 0.4972 - val_acc: 0.8947\n",
      "Epoch 179/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9784\n",
      "Epoch 00179: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0632 - acc: 0.9784 - val_loss: 0.5130 - val_acc: 0.8929\n",
      "Epoch 180/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9796\n",
      "Epoch 00180: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0581 - acc: 0.9797 - val_loss: 0.4534 - val_acc: 0.9028\n",
      "Epoch 181/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9787\n",
      "Epoch 00181: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0621 - acc: 0.9787 - val_loss: 0.4948 - val_acc: 0.8938\n",
      "Epoch 182/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9788\n",
      "Epoch 00182: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0595 - acc: 0.9788 - val_loss: 0.4824 - val_acc: 0.8975\n",
      "Epoch 183/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9803\n",
      "Epoch 00183: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0587 - acc: 0.9802 - val_loss: 0.5338 - val_acc: 0.8949\n",
      "Epoch 184/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9786\n",
      "Epoch 00184: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0613 - acc: 0.9786 - val_loss: 0.4836 - val_acc: 0.8986\n",
      "Epoch 185/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9783\n",
      "Epoch 00185: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0631 - acc: 0.9783 - val_loss: 0.4840 - val_acc: 0.8983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9780\n",
      "Epoch 00186: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0586 - acc: 0.9780 - val_loss: 0.4997 - val_acc: 0.9003\n",
      "Epoch 187/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9790\n",
      "Epoch 00187: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0594 - acc: 0.9790 - val_loss: 0.4805 - val_acc: 0.9014\n",
      "Epoch 188/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9784\n",
      "Epoch 00188: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0624 - acc: 0.9784 - val_loss: 0.4767 - val_acc: 0.9005\n",
      "Epoch 189/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9788\n",
      "Epoch 00189: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0596 - acc: 0.9788 - val_loss: 0.5192 - val_acc: 0.8964\n",
      "Epoch 190/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9780\n",
      "Epoch 00190: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0625 - acc: 0.9780 - val_loss: 0.4658 - val_acc: 0.9017\n",
      "Epoch 191/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9785\n",
      "Epoch 00191: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0616 - acc: 0.9785 - val_loss: 0.5159 - val_acc: 0.8953\n",
      "Epoch 192/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9787\n",
      "Epoch 00192: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0581 - acc: 0.9787 - val_loss: 0.4957 - val_acc: 0.9020\n",
      "Epoch 193/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9792\n",
      "Epoch 00193: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0602 - acc: 0.9791 - val_loss: 0.4971 - val_acc: 0.9004\n",
      "Epoch 194/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9778\n",
      "Epoch 00194: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0601 - acc: 0.9778 - val_loss: 0.4961 - val_acc: 0.8966\n",
      "Epoch 195/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9785\n",
      "Epoch 00195: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0605 - acc: 0.9786 - val_loss: 0.5386 - val_acc: 0.8936\n",
      "Epoch 196/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9787\n",
      "Epoch 00196: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0611 - acc: 0.9787 - val_loss: 0.4745 - val_acc: 0.9011\n",
      "Epoch 197/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9788\n",
      "Epoch 00197: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0591 - acc: 0.9788 - val_loss: 0.5119 - val_acc: 0.8986\n",
      "Epoch 198/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9781\n",
      "Epoch 00198: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0623 - acc: 0.9781 - val_loss: 0.4745 - val_acc: 0.8990\n",
      "Epoch 199/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9778\n",
      "Epoch 00199: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0618 - acc: 0.9778 - val_loss: 0.5264 - val_acc: 0.8952\n",
      "Epoch 200/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9785\n",
      "Epoch 00200: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0613 - acc: 0.9785 - val_loss: 0.4933 - val_acc: 0.9004\n",
      "Epoch 201/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9792\n",
      "Epoch 00201: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0592 - acc: 0.9792 - val_loss: 0.4951 - val_acc: 0.9015\n",
      "Epoch 202/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9782\n",
      "Epoch 00202: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0615 - acc: 0.9782 - val_loss: 0.4704 - val_acc: 0.9006\n",
      "Epoch 203/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9794\n",
      "Epoch 00203: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0594 - acc: 0.9794 - val_loss: 0.4731 - val_acc: 0.9000\n",
      "Epoch 204/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9780\n",
      "Epoch 00204: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0614 - acc: 0.9781 - val_loss: 0.4912 - val_acc: 0.8993\n",
      "Epoch 205/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9788\n",
      "Epoch 00205: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0593 - acc: 0.9788 - val_loss: 0.5151 - val_acc: 0.8977\n",
      "Epoch 206/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9782\n",
      "Epoch 00206: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0617 - acc: 0.9782 - val_loss: 0.4557 - val_acc: 0.9031\n",
      "Epoch 207/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9784\n",
      "Epoch 00207: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0587 - acc: 0.9784 - val_loss: 0.4755 - val_acc: 0.9034\n",
      "Epoch 208/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9780\n",
      "Epoch 00208: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0604 - acc: 0.9781 - val_loss: 0.5053 - val_acc: 0.9002\n",
      "Epoch 209/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9782\n",
      "Epoch 00209: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0617 - acc: 0.9782 - val_loss: 0.4901 - val_acc: 0.9003\n",
      "Epoch 210/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9792\n",
      "Epoch 00210: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0607 - acc: 0.9791 - val_loss: 0.5150 - val_acc: 0.8963\n",
      "Epoch 211/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9783\n",
      "Epoch 00211: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0598 - acc: 0.9783 - val_loss: 0.4693 - val_acc: 0.9002\n",
      "Epoch 212/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9781\n",
      "Epoch 00212: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0621 - acc: 0.9780 - val_loss: 0.4590 - val_acc: 0.9043\n",
      "Epoch 213/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9785\n",
      "Epoch 00213: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0603 - acc: 0.9785 - val_loss: 0.5070 - val_acc: 0.8974\n",
      "Epoch 214/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9785\n",
      "Epoch 00214: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0618 - acc: 0.9785 - val_loss: 0.4934 - val_acc: 0.9025\n",
      "Epoch 215/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9796\n",
      "Epoch 00215: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0583 - acc: 0.9796 - val_loss: 0.4932 - val_acc: 0.8982\n",
      "Epoch 216/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9795\n",
      "Epoch 00216: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0596 - acc: 0.9795 - val_loss: 0.5221 - val_acc: 0.8928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9782\n",
      "Epoch 00217: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0610 - acc: 0.9782 - val_loss: 0.5214 - val_acc: 0.8943\n",
      "Epoch 218/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9789\n",
      "Epoch 00218: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0620 - acc: 0.9788 - val_loss: 0.4945 - val_acc: 0.8988\n",
      "Epoch 219/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9800\n",
      "Epoch 00219: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0570 - acc: 0.9800 - val_loss: 0.4705 - val_acc: 0.8999\n",
      "Epoch 220/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9790\n",
      "Epoch 00220: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0589 - acc: 0.9790 - val_loss: 0.4949 - val_acc: 0.8998\n",
      "Epoch 221/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9796\n",
      "Epoch 00221: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0585 - acc: 0.9796 - val_loss: 0.4809 - val_acc: 0.9020\n",
      "Epoch 222/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9786\n",
      "Epoch 00222: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0607 - acc: 0.9786 - val_loss: 0.5091 - val_acc: 0.8945\n",
      "Epoch 223/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9783\n",
      "Epoch 00223: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0598 - acc: 0.9783 - val_loss: 0.5129 - val_acc: 0.8988\n",
      "Epoch 224/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9796\n",
      "Epoch 00224: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0579 - acc: 0.9796 - val_loss: 0.4758 - val_acc: 0.9009\n",
      "Epoch 225/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9788\n",
      "Epoch 00225: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0595 - acc: 0.9788 - val_loss: 0.4972 - val_acc: 0.8987\n",
      "Epoch 226/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9780\n",
      "Epoch 00226: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0624 - acc: 0.9780 - val_loss: 0.5023 - val_acc: 0.8985\n",
      "Epoch 227/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9791\n",
      "Epoch 00227: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0595 - acc: 0.9791 - val_loss: 0.5298 - val_acc: 0.8972\n",
      "Epoch 228/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9780\n",
      "Epoch 00228: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0626 - acc: 0.9781 - val_loss: 0.4808 - val_acc: 0.8986\n",
      "Epoch 229/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9778\n",
      "Epoch 00229: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9778 - val_loss: 0.5275 - val_acc: 0.8950\n",
      "Epoch 230/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9789\n",
      "Epoch 00230: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0602 - acc: 0.9789 - val_loss: 0.5176 - val_acc: 0.8973\n",
      "Epoch 231/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9792\n",
      "Epoch 00231: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0607 - acc: 0.9792 - val_loss: 0.5378 - val_acc: 0.8924\n",
      "Epoch 232/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9789\n",
      "Epoch 00232: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0599 - acc: 0.9789 - val_loss: 0.5063 - val_acc: 0.8986\n",
      "Epoch 233/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9786\n",
      "Epoch 00233: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0599 - acc: 0.9786 - val_loss: 0.5024 - val_acc: 0.8972\n",
      "Epoch 234/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9782\n",
      "Epoch 00234: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0635 - acc: 0.9782 - val_loss: 0.5068 - val_acc: 0.8947\n",
      "Epoch 235/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9789\n",
      "Epoch 00235: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0602 - acc: 0.9789 - val_loss: 0.5161 - val_acc: 0.8926\n",
      "Epoch 236/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9789\n",
      "Epoch 00236: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0596 - acc: 0.9788 - val_loss: 0.4950 - val_acc: 0.9019\n",
      "Epoch 237/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9806\n",
      "Epoch 00237: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0562 - acc: 0.9805 - val_loss: 0.4899 - val_acc: 0.8988\n",
      "Epoch 238/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9794\n",
      "Epoch 00238: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0569 - acc: 0.9794 - val_loss: 0.4796 - val_acc: 0.9039\n",
      "Epoch 239/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9781\n",
      "Epoch 00239: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0618 - acc: 0.9781 - val_loss: 0.5025 - val_acc: 0.8998\n",
      "Epoch 240/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9788\n",
      "Epoch 00240: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0604 - acc: 0.9787 - val_loss: 0.4775 - val_acc: 0.9018\n",
      "Epoch 241/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9788\n",
      "Epoch 00241: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0615 - acc: 0.9788 - val_loss: 0.4908 - val_acc: 0.8985\n",
      "Epoch 242/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9784\n",
      "Epoch 00242: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0615 - acc: 0.9784 - val_loss: 0.4752 - val_acc: 0.8988\n",
      "Epoch 243/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9788\n",
      "Epoch 00243: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0615 - acc: 0.9788 - val_loss: 0.5152 - val_acc: 0.8947\n",
      "Epoch 244/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9792\n",
      "Epoch 00244: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0595 - acc: 0.9792 - val_loss: 0.5231 - val_acc: 0.8931\n",
      "Epoch 245/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9786\n",
      "Epoch 00245: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0614 - acc: 0.9786 - val_loss: 0.5181 - val_acc: 0.8966\n",
      "Epoch 246/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9785\n",
      "Epoch 00246: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0625 - acc: 0.9785 - val_loss: 0.4859 - val_acc: 0.9014\n",
      "Epoch 247/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9791\n",
      "Epoch 00247: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0590 - acc: 0.9792 - val_loss: 0.4923 - val_acc: 0.8996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9794\n",
      "Epoch 00248: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0593 - acc: 0.9794 - val_loss: 0.4830 - val_acc: 0.9006\n",
      "Epoch 249/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9796\n",
      "Epoch 00249: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0586 - acc: 0.9795 - val_loss: 0.4654 - val_acc: 0.9027\n",
      "Epoch 250/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9788\n",
      "Epoch 00250: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0600 - acc: 0.9788 - val_loss: 0.4947 - val_acc: 0.8999\n",
      "Epoch 251/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9789\n",
      "Epoch 00251: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0594 - acc: 0.9789 - val_loss: 0.4969 - val_acc: 0.8985\n",
      "Epoch 252/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9783\n",
      "Epoch 00252: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0594 - acc: 0.9783 - val_loss: 0.4914 - val_acc: 0.8996\n",
      "Epoch 253/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9790\n",
      "Epoch 00253: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0605 - acc: 0.9790 - val_loss: 0.4829 - val_acc: 0.8985\n",
      "Epoch 254/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9786\n",
      "Epoch 00254: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0608 - acc: 0.9786 - val_loss: 0.4825 - val_acc: 0.9010\n",
      "Epoch 255/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9797\n",
      "Epoch 00255: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0597 - acc: 0.9797 - val_loss: 0.4912 - val_acc: 0.8991\n",
      "Epoch 256/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9772\n",
      "Epoch 00256: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0622 - acc: 0.9772 - val_loss: 0.4891 - val_acc: 0.8977\n",
      "Epoch 257/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9777\n",
      "Epoch 00257: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0638 - acc: 0.9776 - val_loss: 0.5233 - val_acc: 0.8960\n",
      "Epoch 258/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9797\n",
      "Epoch 00258: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0586 - acc: 0.9797 - val_loss: 0.4885 - val_acc: 0.9023\n",
      "Epoch 259/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9794\n",
      "Epoch 00259: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0590 - acc: 0.9794 - val_loss: 0.5297 - val_acc: 0.8941\n",
      "Epoch 260/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9794\n",
      "Epoch 00260: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0600 - acc: 0.9794 - val_loss: 0.4702 - val_acc: 0.9017\n",
      "Epoch 261/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9781\n",
      "Epoch 00261: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0615 - acc: 0.9781 - val_loss: 0.4642 - val_acc: 0.9017\n",
      "Epoch 262/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9786\n",
      "Epoch 00262: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0605 - acc: 0.9787 - val_loss: 0.4972 - val_acc: 0.8968\n",
      "Epoch 263/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9790\n",
      "Epoch 00263: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0568 - acc: 0.9789 - val_loss: 0.5195 - val_acc: 0.8952\n",
      "Epoch 264/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9792\n",
      "Epoch 00264: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0593 - acc: 0.9791 - val_loss: 0.4877 - val_acc: 0.8989\n",
      "Epoch 265/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9799\n",
      "Epoch 00265: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0598 - acc: 0.9800 - val_loss: 0.4850 - val_acc: 0.9017\n",
      "Epoch 266/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9783\n",
      "Epoch 00266: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0593 - acc: 0.9783 - val_loss: 0.5209 - val_acc: 0.8970\n",
      "Epoch 267/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9779\n",
      "Epoch 00267: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0612 - acc: 0.9779 - val_loss: 0.4962 - val_acc: 0.8987\n",
      "Epoch 268/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9784\n",
      "Epoch 00268: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0605 - acc: 0.9783 - val_loss: 0.5053 - val_acc: 0.8988\n",
      "Epoch 269/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9799\n",
      "Epoch 00269: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0578 - acc: 0.9799 - val_loss: 0.4934 - val_acc: 0.9003\n",
      "Epoch 270/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9799\n",
      "Epoch 00270: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0575 - acc: 0.9798 - val_loss: 0.4748 - val_acc: 0.9036\n",
      "Epoch 271/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9783\n",
      "Epoch 00271: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0610 - acc: 0.9784 - val_loss: 0.5243 - val_acc: 0.8974\n",
      "Epoch 272/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9785\n",
      "Epoch 00272: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0605 - acc: 0.9785 - val_loss: 0.4668 - val_acc: 0.9012\n",
      "Epoch 273/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9791\n",
      "Epoch 00273: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0595 - acc: 0.9791 - val_loss: 0.4976 - val_acc: 0.8986\n",
      "Epoch 274/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9789\n",
      "Epoch 00274: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0597 - acc: 0.9788 - val_loss: 0.4742 - val_acc: 0.9022\n",
      "Epoch 275/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9798\n",
      "Epoch 00275: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0566 - acc: 0.9798 - val_loss: 0.4976 - val_acc: 0.8995\n",
      "Epoch 276/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9777\n",
      "Epoch 00276: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0644 - acc: 0.9776 - val_loss: 0.5057 - val_acc: 0.8990\n",
      "Epoch 277/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9801\n",
      "Epoch 00277: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0582 - acc: 0.9800 - val_loss: 0.5168 - val_acc: 0.8952\n",
      "Epoch 278/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9789\n",
      "Epoch 00278: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0613 - acc: 0.9788 - val_loss: 0.4851 - val_acc: 0.8994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9787\n",
      "Epoch 00279: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0599 - acc: 0.9787 - val_loss: 0.5105 - val_acc: 0.8990\n",
      "Epoch 280/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9793\n",
      "Epoch 00280: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0584 - acc: 0.9793 - val_loss: 0.4922 - val_acc: 0.9001\n",
      "Epoch 281/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9790\n",
      "Epoch 00281: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0600 - acc: 0.9790 - val_loss: 0.4742 - val_acc: 0.9017\n",
      "Epoch 282/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9790\n",
      "Epoch 00282: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0588 - acc: 0.9791 - val_loss: 0.4781 - val_acc: 0.9023\n",
      "Epoch 283/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9793\n",
      "Epoch 00283: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0592 - acc: 0.9793 - val_loss: 0.4897 - val_acc: 0.8965\n",
      "Epoch 284/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9794\n",
      "Epoch 00284: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0587 - acc: 0.9793 - val_loss: 0.4731 - val_acc: 0.9019\n",
      "Epoch 285/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9781\n",
      "Epoch 00285: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.4792 - val_acc: 0.9001\n",
      "Epoch 286/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9787\n",
      "Epoch 00286: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0609 - acc: 0.9787 - val_loss: 0.4671 - val_acc: 0.9008\n",
      "Epoch 287/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9789\n",
      "Epoch 00287: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0588 - acc: 0.9789 - val_loss: 0.4745 - val_acc: 0.9027\n",
      "Epoch 288/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9791\n",
      "Epoch 00288: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0604 - acc: 0.9791 - val_loss: 0.4816 - val_acc: 0.8988\n",
      "Epoch 289/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9788\n",
      "Epoch 00289: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0600 - acc: 0.9788 - val_loss: 0.5539 - val_acc: 0.8915\n",
      "Epoch 290/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9799\n",
      "Epoch 00290: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0575 - acc: 0.9799 - val_loss: 0.4779 - val_acc: 0.9033\n",
      "Epoch 291/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9789\n",
      "Epoch 00291: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0595 - acc: 0.9789 - val_loss: 0.5198 - val_acc: 0.8961\n",
      "Epoch 292/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9798\n",
      "Epoch 00292: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0563 - acc: 0.9798 - val_loss: 0.5274 - val_acc: 0.8936\n",
      "Epoch 293/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9787\n",
      "Epoch 00293: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0603 - acc: 0.9786 - val_loss: 0.4649 - val_acc: 0.9045\n",
      "Epoch 294/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9794\n",
      "Epoch 00294: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0590 - acc: 0.9794 - val_loss: 0.4840 - val_acc: 0.8985\n",
      "Epoch 295/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9791\n",
      "Epoch 00295: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0596 - acc: 0.9791 - val_loss: 0.5049 - val_acc: 0.8983\n",
      "Epoch 296/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9784\n",
      "Epoch 00296: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0599 - acc: 0.9784 - val_loss: 0.5098 - val_acc: 0.8952\n",
      "Epoch 297/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9783\n",
      "Epoch 00297: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0601 - acc: 0.9783 - val_loss: 0.5003 - val_acc: 0.8986\n",
      "Epoch 298/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9790\n",
      "Epoch 00298: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0596 - acc: 0.9790 - val_loss: 0.5248 - val_acc: 0.8952\n",
      "Epoch 299/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9793\n",
      "Epoch 00299: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0582 - acc: 0.9793 - val_loss: 0.5049 - val_acc: 0.8952\n",
      "Epoch 300/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9785\n",
      "Epoch 00300: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0603 - acc: 0.9785 - val_loss: 0.4867 - val_acc: 0.8984\n",
      "Epoch 301/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9780\n",
      "Epoch 00301: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0603 - acc: 0.9780 - val_loss: 0.5214 - val_acc: 0.8933\n",
      "Epoch 302/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9786\n",
      "Epoch 00302: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0592 - acc: 0.9786 - val_loss: 0.4972 - val_acc: 0.9015\n",
      "Epoch 303/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9800\n",
      "Epoch 00303: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0592 - acc: 0.9800 - val_loss: 0.4886 - val_acc: 0.9015\n",
      "Epoch 304/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9793\n",
      "Epoch 00304: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0592 - acc: 0.9794 - val_loss: 0.4808 - val_acc: 0.9028\n",
      "Epoch 305/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9793\n",
      "Epoch 00305: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0591 - acc: 0.9793 - val_loss: 0.4850 - val_acc: 0.9017\n",
      "Epoch 306/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9791\n",
      "Epoch 00306: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0597 - acc: 0.9791 - val_loss: 0.4853 - val_acc: 0.9032\n",
      "Epoch 307/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9791\n",
      "Epoch 00307: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0592 - acc: 0.9790 - val_loss: 0.5040 - val_acc: 0.8991\n",
      "Epoch 308/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9798\n",
      "Epoch 00308: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0588 - acc: 0.9797 - val_loss: 0.5014 - val_acc: 0.8999\n",
      "Epoch 309/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9791\n",
      "Epoch 00309: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0593 - acc: 0.9791 - val_loss: 0.4771 - val_acc: 0.9024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9793\n",
      "Epoch 00310: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0575 - acc: 0.9793 - val_loss: 0.5064 - val_acc: 0.8986\n",
      "Epoch 311/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9791\n",
      "Epoch 00311: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0596 - acc: 0.9791 - val_loss: 0.4957 - val_acc: 0.8984\n",
      "Epoch 312/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9796\n",
      "Epoch 00312: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0583 - acc: 0.9795 - val_loss: 0.5362 - val_acc: 0.8964\n",
      "Epoch 313/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9782\n",
      "Epoch 00313: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0604 - acc: 0.9783 - val_loss: 0.5205 - val_acc: 0.8953\n",
      "Epoch 314/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9792\n",
      "Epoch 00314: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0582 - acc: 0.9792 - val_loss: 0.4991 - val_acc: 0.9011\n",
      "Epoch 315/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9790\n",
      "Epoch 00315: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0604 - acc: 0.9790 - val_loss: 0.5305 - val_acc: 0.8970\n",
      "Epoch 316/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9784\n",
      "Epoch 00316: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0606 - acc: 0.9784 - val_loss: 0.5020 - val_acc: 0.8959\n",
      "Epoch 317/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9789\n",
      "Epoch 00317: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0614 - acc: 0.9789 - val_loss: 0.4548 - val_acc: 0.9012\n",
      "Epoch 318/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9791\n",
      "Epoch 00318: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0597 - acc: 0.9790 - val_loss: 0.5197 - val_acc: 0.8938\n",
      "Epoch 319/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9790\n",
      "Epoch 00319: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0614 - acc: 0.9790 - val_loss: 0.4989 - val_acc: 0.8988\n",
      "Epoch 320/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9782\n",
      "Epoch 00320: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0617 - acc: 0.9782 - val_loss: 0.5048 - val_acc: 0.8968\n",
      "Epoch 321/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9786\n",
      "Epoch 00321: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0604 - acc: 0.9786 - val_loss: 0.4733 - val_acc: 0.8975\n",
      "Epoch 322/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9784\n",
      "Epoch 00322: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0599 - acc: 0.9784 - val_loss: 0.4845 - val_acc: 0.9005\n",
      "Epoch 323/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9788\n",
      "Epoch 00323: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0591 - acc: 0.9787 - val_loss: 0.5136 - val_acc: 0.8947\n",
      "Epoch 324/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9780\n",
      "Epoch 00324: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0605 - acc: 0.9780 - val_loss: 0.5072 - val_acc: 0.8974\n",
      "Epoch 325/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9800\n",
      "Epoch 00325: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0584 - acc: 0.9800 - val_loss: 0.4954 - val_acc: 0.8984\n",
      "Epoch 326/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9779\n",
      "Epoch 00326: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0614 - acc: 0.9779 - val_loss: 0.4845 - val_acc: 0.9014\n",
      "Epoch 327/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9798\n",
      "Epoch 00327: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0592 - acc: 0.9798 - val_loss: 0.5081 - val_acc: 0.8950\n",
      "Epoch 328/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9791\n",
      "Epoch 00328: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0597 - acc: 0.9791 - val_loss: 0.5386 - val_acc: 0.8929\n",
      "Epoch 329/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9792\n",
      "Epoch 00329: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0587 - acc: 0.9792 - val_loss: 0.4967 - val_acc: 0.9004\n",
      "Epoch 330/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9792\n",
      "Epoch 00330: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0601 - acc: 0.9792 - val_loss: 0.5004 - val_acc: 0.8950\n",
      "Epoch 331/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9792\n",
      "Epoch 00331: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0598 - acc: 0.9792 - val_loss: 0.5068 - val_acc: 0.8982\n",
      "Epoch 332/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9797\n",
      "Epoch 00332: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0564 - acc: 0.9797 - val_loss: 0.5209 - val_acc: 0.8949\n",
      "Epoch 333/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9785\n",
      "Epoch 00333: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 91ms/step - loss: 0.0604 - acc: 0.9785 - val_loss: 0.5261 - val_acc: 0.8939\n",
      "Epoch 334/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9790\n",
      "Epoch 00334: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0588 - acc: 0.9790 - val_loss: 0.5120 - val_acc: 0.8982\n",
      "Epoch 335/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9791\n",
      "Epoch 00335: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0598 - acc: 0.9791 - val_loss: 0.5150 - val_acc: 0.8961\n",
      "Epoch 336/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9793\n",
      "Epoch 00336: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0575 - acc: 0.9792 - val_loss: 0.4864 - val_acc: 0.9030\n",
      "Epoch 337/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9785\n",
      "Epoch 00337: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0613 - acc: 0.9785 - val_loss: 0.5307 - val_acc: 0.8948\n",
      "Epoch 338/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9793\n",
      "Epoch 00338: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0590 - acc: 0.9794 - val_loss: 0.5481 - val_acc: 0.8931\n",
      "Epoch 339/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9791\n",
      "Epoch 00339: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0608 - acc: 0.9791 - val_loss: 0.4931 - val_acc: 0.8985\n",
      "Epoch 340/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9786\n",
      "Epoch 00340: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.0597 - acc: 0.9786 - val_loss: 0.4815 - val_acc: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9780\n",
      "Epoch 00341: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0625 - acc: 0.9779 - val_loss: 0.5012 - val_acc: 0.8942\n",
      "Epoch 342/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9798\n",
      "Epoch 00342: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0577 - acc: 0.9798 - val_loss: 0.4950 - val_acc: 0.9000\n",
      "Epoch 343/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9799\n",
      "Epoch 00343: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0572 - acc: 0.9799 - val_loss: 0.4936 - val_acc: 0.8998\n",
      "Epoch 344/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9792\n",
      "Epoch 00344: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0607 - acc: 0.9793 - val_loss: 0.5120 - val_acc: 0.8973\n",
      "Epoch 345/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9802\n",
      "Epoch 00345: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0564 - acc: 0.9801 - val_loss: 0.5271 - val_acc: 0.8943\n",
      "Epoch 346/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9797\n",
      "Epoch 00346: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0578 - acc: 0.9797 - val_loss: 0.4957 - val_acc: 0.8984\n",
      "Epoch 347/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9798\n",
      "Epoch 00347: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0567 - acc: 0.9798 - val_loss: 0.5177 - val_acc: 0.8935\n",
      "Epoch 348/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9789\n",
      "Epoch 00348: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0590 - acc: 0.9789 - val_loss: 0.5347 - val_acc: 0.8910\n",
      "Epoch 349/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9789\n",
      "Epoch 00349: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0587 - acc: 0.9789 - val_loss: 0.4983 - val_acc: 0.9015\n",
      "Epoch 350/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9794\n",
      "Epoch 00350: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0569 - acc: 0.9794 - val_loss: 0.4853 - val_acc: 0.9013\n",
      "Epoch 351/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9777\n",
      "Epoch 00351: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0618 - acc: 0.9777 - val_loss: 0.5041 - val_acc: 0.8970\n",
      "Epoch 352/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9785\n",
      "Epoch 00352: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0604 - acc: 0.9785 - val_loss: 0.4840 - val_acc: 0.9025\n",
      "Epoch 353/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9796\n",
      "Epoch 00353: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0564 - acc: 0.9796 - val_loss: 0.4982 - val_acc: 0.9002\n",
      "Epoch 354/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9786\n",
      "Epoch 00354: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0609 - acc: 0.9787 - val_loss: 0.5029 - val_acc: 0.8982\n",
      "Epoch 355/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9788\n",
      "Epoch 00355: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0601 - acc: 0.9788 - val_loss: 0.5041 - val_acc: 0.8975\n",
      "Epoch 356/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9771\n",
      "Epoch 00356: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0646 - acc: 0.9771 - val_loss: 0.4960 - val_acc: 0.8998\n",
      "Epoch 357/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9794\n",
      "Epoch 00357: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 94ms/step - loss: 0.0580 - acc: 0.9794 - val_loss: 0.4905 - val_acc: 0.9019\n",
      "Epoch 358/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9794\n",
      "Epoch 00358: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0584 - acc: 0.9794 - val_loss: 0.4745 - val_acc: 0.9031\n",
      "Epoch 359/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9791\n",
      "Epoch 00359: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0572 - acc: 0.9790 - val_loss: 0.4758 - val_acc: 0.8986\n",
      "Epoch 360/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9791\n",
      "Epoch 00360: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0596 - acc: 0.9791 - val_loss: 0.5036 - val_acc: 0.8992\n",
      "Epoch 361/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9788\n",
      "Epoch 00361: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0581 - acc: 0.9788 - val_loss: 0.4916 - val_acc: 0.8976\n",
      "Epoch 362/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9790\n",
      "Epoch 00362: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0598 - acc: 0.9790 - val_loss: 0.4924 - val_acc: 0.8966\n",
      "Epoch 363/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9796\n",
      "Epoch 00363: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0601 - acc: 0.9796 - val_loss: 0.5042 - val_acc: 0.9003\n",
      "Epoch 364/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9792\n",
      "Epoch 00364: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0591 - acc: 0.9792 - val_loss: 0.4826 - val_acc: 0.9016\n",
      "Epoch 365/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9795\n",
      "Epoch 00365: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0593 - acc: 0.9796 - val_loss: 0.4846 - val_acc: 0.9021\n",
      "Epoch 366/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9797\n",
      "Epoch 00366: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0566 - acc: 0.9796 - val_loss: 0.4738 - val_acc: 0.9018\n",
      "Epoch 367/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9802\n",
      "Epoch 00367: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0581 - acc: 0.9802 - val_loss: 0.5207 - val_acc: 0.8973\n",
      "Epoch 368/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9787\n",
      "Epoch 00368: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0598 - acc: 0.9786 - val_loss: 0.4850 - val_acc: 0.9014\n",
      "Epoch 369/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9785\n",
      "Epoch 00369: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0607 - acc: 0.9785 - val_loss: 0.5267 - val_acc: 0.8949\n",
      "Epoch 370/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9798\n",
      "Epoch 00370: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0579 - acc: 0.9799 - val_loss: 0.4669 - val_acc: 0.9024\n",
      "Epoch 371/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9804\n",
      "Epoch 00371: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0573 - acc: 0.9804 - val_loss: 0.4899 - val_acc: 0.9013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9785\n",
      "Epoch 00372: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0601 - acc: 0.9785 - val_loss: 0.5151 - val_acc: 0.8963\n",
      "Epoch 373/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9798\n",
      "Epoch 00373: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0590 - acc: 0.9798 - val_loss: 0.4966 - val_acc: 0.8975\n",
      "Epoch 374/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9799\n",
      "Epoch 00374: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0567 - acc: 0.9799 - val_loss: 0.5042 - val_acc: 0.8990\n",
      "Epoch 375/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9795\n",
      "Epoch 00375: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0586 - acc: 0.9795 - val_loss: 0.4630 - val_acc: 0.9037\n",
      "Epoch 376/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9783\n",
      "Epoch 00376: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0618 - acc: 0.9783 - val_loss: 0.4879 - val_acc: 0.9025\n",
      "Epoch 377/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9799\n",
      "Epoch 00377: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0573 - acc: 0.9798 - val_loss: 0.4720 - val_acc: 0.9041\n",
      "Epoch 378/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9794\n",
      "Epoch 00378: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0585 - acc: 0.9793 - val_loss: 0.5081 - val_acc: 0.8979\n",
      "Epoch 379/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9793\n",
      "Epoch 00379: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0584 - acc: 0.9793 - val_loss: 0.4982 - val_acc: 0.9000\n",
      "Epoch 380/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9785\n",
      "Epoch 00380: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0599 - acc: 0.9784 - val_loss: 0.5084 - val_acc: 0.8988\n",
      "Epoch 381/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9804\n",
      "Epoch 00381: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 90ms/step - loss: 0.0566 - acc: 0.9804 - val_loss: 0.4756 - val_acc: 0.9030\n",
      "Epoch 382/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9787\n",
      "Epoch 00382: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 35s 91ms/step - loss: 0.0595 - acc: 0.9787 - val_loss: 0.4572 - val_acc: 0.9028\n",
      "Epoch 383/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9797\n",
      "Epoch 00383: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0564 - acc: 0.9797 - val_loss: 0.5141 - val_acc: 0.8981\n",
      "Epoch 384/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9802\n",
      "Epoch 00384: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 96ms/step - loss: 0.0577 - acc: 0.9802 - val_loss: 0.5190 - val_acc: 0.8947\n",
      "Epoch 385/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9792\n",
      "Epoch 00385: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0600 - acc: 0.9791 - val_loss: 0.5207 - val_acc: 0.8933\n",
      "Epoch 386/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9796\n",
      "Epoch 00386: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0581 - acc: 0.9796 - val_loss: 0.4776 - val_acc: 0.9006\n",
      "Epoch 387/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9797\n",
      "Epoch 00387: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0575 - acc: 0.9797 - val_loss: 0.5218 - val_acc: 0.8967\n",
      "Epoch 388/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9787\n",
      "Epoch 00388: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0598 - acc: 0.9787 - val_loss: 0.5106 - val_acc: 0.8985\n",
      "Epoch 389/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9789\n",
      "Epoch 00389: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0613 - acc: 0.9789 - val_loss: 0.4901 - val_acc: 0.9006\n",
      "Epoch 390/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9784\n",
      "Epoch 00390: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0607 - acc: 0.9784 - val_loss: 0.5047 - val_acc: 0.8992\n",
      "Epoch 391/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9793\n",
      "Epoch 00391: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0599 - acc: 0.9793 - val_loss: 0.5360 - val_acc: 0.8954\n",
      "Epoch 392/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9789\n",
      "Epoch 00392: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 94ms/step - loss: 0.0582 - acc: 0.9789 - val_loss: 0.5410 - val_acc: 0.8948\n",
      "Epoch 393/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9788\n",
      "Epoch 00393: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0592 - acc: 0.9787 - val_loss: 0.4732 - val_acc: 0.9004\n",
      "Epoch 394/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9792\n",
      "Epoch 00394: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0585 - acc: 0.9792 - val_loss: 0.5085 - val_acc: 0.8971\n",
      "Epoch 395/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9807\n",
      "Epoch 00395: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0563 - acc: 0.9807 - val_loss: 0.4811 - val_acc: 0.9003\n",
      "Epoch 396/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9793\n",
      "Epoch 00396: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0577 - acc: 0.9793 - val_loss: 0.4844 - val_acc: 0.9029\n",
      "Epoch 397/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9796\n",
      "Epoch 00397: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0567 - acc: 0.9796 - val_loss: 0.4808 - val_acc: 0.9023\n",
      "Epoch 398/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9786\n",
      "Epoch 00398: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0590 - acc: 0.9787 - val_loss: 0.4816 - val_acc: 0.9001\n",
      "Epoch 399/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9790\n",
      "Epoch 00399: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.0590 - acc: 0.9791 - val_loss: 0.4912 - val_acc: 0.9017\n",
      "Epoch 400/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9807\n",
      "Epoch 00400: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.0546 - acc: 0.9807 - val_loss: 0.4910 - val_acc: 0.8995\n",
      "Epoch 401/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9792\n",
      "Epoch 00401: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 38s 97ms/step - loss: 0.0586 - acc: 0.9791 - val_loss: 0.4879 - val_acc: 0.8988\n",
      "Epoch 402/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9801\n",
      "Epoch 00402: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 95ms/step - loss: 0.0562 - acc: 0.9801 - val_loss: 0.5160 - val_acc: 0.8973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9792\n",
      "Epoch 00403: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0580 - acc: 0.9793 - val_loss: 0.5020 - val_acc: 0.8972\n",
      "Epoch 404/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9781\n",
      "Epoch 00404: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0618 - acc: 0.9782 - val_loss: 0.5322 - val_acc: 0.8926\n",
      "Epoch 405/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9796\n",
      "Epoch 00405: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0593 - acc: 0.9796 - val_loss: 0.4873 - val_acc: 0.9007\n",
      "Epoch 406/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9794\n",
      "Epoch 00406: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 94ms/step - loss: 0.0591 - acc: 0.9794 - val_loss: 0.4654 - val_acc: 0.9032\n",
      "Epoch 407/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9791\n",
      "Epoch 00407: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0582 - acc: 0.9791 - val_loss: 0.5264 - val_acc: 0.8995\n",
      "Epoch 408/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9790\n",
      "Epoch 00408: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0613 - acc: 0.9790 - val_loss: 0.4700 - val_acc: 0.9001\n",
      "Epoch 409/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9789\n",
      "Epoch 00409: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0597 - acc: 0.9789 - val_loss: 0.4711 - val_acc: 0.9016\n",
      "Epoch 410/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9788\n",
      "Epoch 00410: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0604 - acc: 0.9787 - val_loss: 0.5208 - val_acc: 0.8954\n",
      "Epoch 411/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9801\n",
      "Epoch 00411: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0574 - acc: 0.9802 - val_loss: 0.5156 - val_acc: 0.8949\n",
      "Epoch 412/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9788\n",
      "Epoch 00412: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0586 - acc: 0.9788 - val_loss: 0.4859 - val_acc: 0.9011\n",
      "Epoch 413/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9792\n",
      "Epoch 00413: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 93ms/step - loss: 0.0587 - acc: 0.9792 - val_loss: 0.4908 - val_acc: 0.9017\n",
      "Epoch 414/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9797\n",
      "Epoch 00414: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 37s 94ms/step - loss: 0.0573 - acc: 0.9797 - val_loss: 0.5039 - val_acc: 0.8996\n",
      "Epoch 415/10000\n",
      "389/390 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9793\n",
      "Epoch 00415: val_acc did not improve from 0.90585\n",
      "390/390 [==============================] - 36s 92ms/step - loss: 0.0583 - acc: 0.9793 - val_loss: 0.4854 - val_acc: 0.9012\n",
      "Epoch 416/10000\n",
      "289/390 [=====================>........] - ETA: 8s - loss: 0.0610 - acc: 0.9791"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4769a09fc93a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 171\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2978\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs, learning_rate, batch_size = 10000, 0.001, 128\n",
    "\n",
    "train_generator = CIFAR10Sequence(train_x, train_y, batch_size)\n",
    "test_generator = CIFAR10Sequence(test_x, test_y, batch_size)\n",
    "\n",
    "filepath=\"weights_d3.best.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.load_weights(filepath)\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=(len(train_x) // batch_size),\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=(len(test_x) // batch_size),\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
